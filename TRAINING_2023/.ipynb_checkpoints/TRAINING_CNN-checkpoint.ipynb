{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import sys\n",
    "import netCDF4 as nc4\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "sys.path.append(\"/home2/datahome/tpicard/python/Python_Modules_p3_pyticles/\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from CNN_tools import *\n",
    "from CNN_UNET import *\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from DATALOADER import Pdf_Image_DataSet, Pdf_Image_DataSet_image_process\n",
    "from variables import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN TYPE ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save direction and type of cnn\n",
    "cnn_type == '4L'\n",
    "if cnn_type == '4L':\n",
    "    autoencoder = CNN_UNET_4L()\n",
    "    filename_chkpt = 'CNN_UNET_4L_2.0'\n",
    "elif cnn_type =='surf':\n",
    "    \n",
    "    autoencoder = CNN_UNET_SURF()\n",
    "    filename_chkpt = 'CNN_UNET_SURF'\n",
    "    \n",
    "dirSAVE = './Saved_model'\n",
    "checkpoint_callback = ModelCheckpoint(monitor='loss_filter_200m_validation',\n",
    "                                              dirpath= dirSAVE,\n",
    "                                              filename= filename_chkpt + '-{epoch:02d}-{loss_filter_200m_validation:.2f}',\n",
    "                                              save_top_k=2,\n",
    "                                              mode='min')\n",
    "dirLOG = './logs/{0}/'.format(filename_chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATA ####\n",
    "\n",
    "image_train = load_images_train('half')\n",
    "#image_norm_train = load_images_train()\n",
    "\n",
    "pdf_train = load_pdf_train()\n",
    "pdf_filter_train = load_pdf_filter_train()\n",
    "\n",
    "pdf_train = load_pdf_train()\n",
    "pdf_filter_train = load_pdf_filter_train()\n",
    "\n",
    "pdf_train = np.transpose(pdf_train,(0,2,1,3,4))\n",
    "pdf_train = pdf_train.reshape(pdf_train.shape[0]*pdf_train.shape[1],8,100,100)\n",
    "pdf_train = pdf_train[::2]\n",
    "\n",
    "pdf_filter_train = np.transpose(pdf_filter_train,(0,2,1,3,4))\n",
    "pdf_filter_train = pdf_filter_train.reshape(pdf_filter_train.shape[0]*pdf_filter_train.shape[1],8,100,100)\n",
    "pdf_filter_train = pdf_filter_train[::2]\n",
    "\n",
    "#image_norm_eval = load_image_processed('validation')\n",
    "image_eval = load_images_validation()\n",
    "pdf_eval = load_pdf_validation()\n",
    "pdf_filter_eval = load_pdf_filter_validation()\n",
    "\n",
    "\n",
    "pdf_eval = np.transpose(pdf_eval,(0,2,1,3,4))\n",
    "pdf_eval = pdf_eval.reshape(pdf_eval.shape[0]*pdf_eval.shape[1],8,100,100)\n",
    "\n",
    "pdf_filter_eval = np.transpose(pdf_filter_eval,(0,2,1,3,4))\n",
    "pdf_filter_eval = pdf_filter_eval.reshape(pdf_filter_eval.shape[0]*pdf_filter_eval.shape[1],8,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4302, 68, 100, 100])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4302, 8, 100, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2aab6e329a60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh((pdf_train[20,-1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2aab6db55d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh((pdf_filter_train[20,-1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7c7273e95f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlist_mean_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlist_std_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/conda-env/croco/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3368\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# MEAN and STD for each channel\n",
    "list_mean_train = []\n",
    "list_std_train = []\n",
    "\n",
    "\n",
    "for i in range(image_train.shape[1]):\n",
    "    list_mean_train.append(np.mean(image_train[:,i,:,:]))\n",
    "    list_std_train.append(np.std(image_train[:,i,:,:]))\n",
    "\n",
    "\n",
    "# Normalization of inputs\n",
    "Normalize = transforms.Normalize(list_mean_train, list_std_train)\n",
    "image_eval = Normalize(torch.tensor(image_eval))\n",
    "image_train = Normalize(torch.tensor(image_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6965)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(image_train[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAINING AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## reduce size dataset\n",
    "                       \n",
    "#train_set = Pdf_Image_DataSet_image_process(image_norm_train,pdf_train,pdf_filter_train,transform= ToTensor())\n",
    "#eval_set = Pdf_Image_DataSet_image_process(image_norm_eval,pdf_eval,pdf_filter_eval,transform= ToTensor())\n",
    "\n",
    "train_set = Pdf_Image_DataSet(image_train,pdf_train,pdf_filter_train,transform= ToTensor())\n",
    "eval_set = Pdf_Image_DataSet(image_eval,pdf_eval,pdf_filter_eval,transform= ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=False)\n",
    "\n",
    "\n",
    "eval_loader = DataLoader(eval_set, batch_size=batch_size, num_workers = 0, shuffle = False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-dcb0ca9d-55d4-28a2-1aa7-2638e1a18e28]\n",
      "\n",
      "   | Name       | Type            | Params\n",
      "------------------------------------------------\n",
      "0  | conv1      | Sequential      | 80.9 K\n",
      "1  | conv2      | Sequential      | 221 K \n",
      "2  | conv3      | Sequential      | 885 K \n",
      "3  | conv_up1   | Sequential      | 115 K \n",
      "4  | conv_up2   | Sequential      | 442 K \n",
      "5  | convTrans3 | ConvTranspose2d | 131 K \n",
      "6  | convTrans2 | ConvTranspose2d | 32.8 K\n",
      "7  | softmax    | Softmax         | 0     \n",
      "8  | flatten    | Flatten         | 0     \n",
      "9  | maxpool2d  | MaxPool2d       | 0     \n",
      "10 | avgpool2d  | AvgPool2d       | 0     \n",
      "11 | relu       | ReLU            | 0     \n",
      "------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.643     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 135/174 [00:21<00:06,  6.32it/s, loss=0.58, v_num=8] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 137/174 [00:21<00:05,  6.38it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  80%|████████  | 140/174 [00:21<00:05,  6.43it/s, loss=0.58, v_num=8]\n",
      "Validating:  13%|█▎        | 5/39 [00:00<00:03, 10.63it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 143/174 [00:22<00:04,  6.49it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  84%|████████▍ | 146/174 [00:22<00:04,  6.55it/s, loss=0.58, v_num=8]\n",
      "Validating:  28%|██▊       | 11/39 [00:01<00:02, 10.94it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 149/174 [00:22<00:03,  6.60it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  87%|████████▋ | 152/174 [00:22<00:03,  6.65it/s, loss=0.58, v_num=8]\n",
      "Validating:  44%|████▎     | 17/39 [00:01<00:01, 11.05it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 155/174 [00:23<00:02,  6.71it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  91%|█████████ | 158/174 [00:23<00:02,  6.76it/s, loss=0.58, v_num=8]\n",
      "Validating:  59%|█████▉    | 23/39 [00:02<00:01, 11.07it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 161/174 [00:23<00:01,  6.81it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  94%|█████████▍| 164/174 [00:23<00:01,  6.86it/s, loss=0.58, v_num=8]\n",
      "Validating:  74%|███████▍  | 29/39 [00:02<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 167/174 [00:24<00:01,  6.90it/s, loss=0.58, v_num=8]\n",
      "Epoch 0:  98%|█████████▊| 170/174 [00:24<00:00,  6.95it/s, loss=0.58, v_num=8]\n",
      "Validating:  90%|████████▉ | 35/39 [00:03<00:00, 11.11it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 174/174 [00:24<00:00,  7.01it/s, loss=0.58, v_num=8]\n",
      "Epoch 1:  78%|███████▊  | 135/174 [00:21<00:06,  6.33it/s, loss=0.348, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 138/174 [00:21<00:05,  6.41it/s, loss=0.348, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.33it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 141/174 [00:21<00:05,  6.47it/s, loss=0.348, v_num=8]\n",
      "Epoch 1:  83%|████████▎ | 144/174 [00:22<00:04,  6.53it/s, loss=0.348, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 11.00it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 147/174 [00:22<00:04,  6.58it/s, loss=0.348, v_num=8]\n",
      "Epoch 1:  86%|████████▌ | 150/174 [00:22<00:03,  6.64it/s, loss=0.348, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.13it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 153/174 [00:22<00:03,  6.69it/s, loss=0.348, v_num=8]\n",
      "Epoch 1:  90%|████████▉ | 156/174 [00:23<00:02,  6.74it/s, loss=0.348, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.17it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 159/174 [00:23<00:02,  6.79it/s, loss=0.348, v_num=8]\n",
      "Epoch 1:  93%|█████████▎| 162/174 [00:23<00:01,  6.84it/s, loss=0.348, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.17it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 165/174 [00:23<00:01,  6.89it/s, loss=0.348, v_num=8]\n",
      "Epoch 1:  97%|█████████▋| 168/174 [00:24<00:00,  6.94it/s, loss=0.348, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:02<00:00, 11.17it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 171/174 [00:24<00:00,  6.99it/s, loss=0.348, v_num=8]\n",
      "Epoch 1: 100%|██████████| 174/174 [00:24<00:00,  7.03it/s, loss=0.348, v_num=8]\n",
      "Epoch 2:  78%|███████▊  | 135/174 [00:21<00:06,  6.31it/s, loss=0.263, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 138/174 [00:21<00:05,  6.39it/s, loss=0.263, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.25it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 141/174 [00:21<00:05,  6.45it/s, loss=0.263, v_num=8]\n",
      "Epoch 2:  83%|████████▎ | 144/174 [00:22<00:04,  6.50it/s, loss=0.263, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.95it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 147/174 [00:22<00:04,  6.56it/s, loss=0.263, v_num=8]\n",
      "Epoch 2:  86%|████████▌ | 150/174 [00:22<00:03,  6.61it/s, loss=0.263, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 10.75it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 153/174 [00:22<00:03,  6.66it/s, loss=0.263, v_num=8]\n",
      "Epoch 2:  90%|████████▉ | 156/174 [00:23<00:02,  6.71it/s, loss=0.263, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.00it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 159/174 [00:23<00:02,  6.76it/s, loss=0.263, v_num=8]\n",
      "Epoch 2:  93%|█████████▎| 162/174 [00:23<00:01,  6.81it/s, loss=0.263, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.09it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 165/174 [00:24<00:01,  6.86it/s, loss=0.263, v_num=8]\n",
      "Epoch 2:  97%|█████████▋| 168/174 [00:24<00:00,  6.91it/s, loss=0.263, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.13it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 171/174 [00:24<00:00,  6.96it/s, loss=0.263, v_num=8]\n",
      "Epoch 2: 100%|██████████| 174/174 [00:24<00:00,  7.00it/s, loss=0.263, v_num=8]\n",
      "Epoch 3:  78%|███████▊  | 135/174 [00:21<00:06,  6.31it/s, loss=0.231, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 138/174 [00:21<00:05,  6.39it/s, loss=0.231, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.23it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 141/174 [00:21<00:05,  6.45it/s, loss=0.231, v_num=8]\n",
      "Epoch 3:  83%|████████▎ | 144/174 [00:22<00:04,  6.50it/s, loss=0.231, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.98it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 147/174 [00:22<00:04,  6.56it/s, loss=0.231, v_num=8]\n",
      "Epoch 3:  86%|████████▌ | 150/174 [00:22<00:03,  6.61it/s, loss=0.231, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.11it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 153/174 [00:22<00:03,  6.67it/s, loss=0.231, v_num=8]\n",
      "Epoch 3:  90%|████████▉ | 156/174 [00:23<00:02,  6.72it/s, loss=0.231, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.13it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 159/174 [00:23<00:02,  6.77it/s, loss=0.231, v_num=8]\n",
      "Epoch 3:  93%|█████████▎| 162/174 [00:23<00:01,  6.82it/s, loss=0.231, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.14it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 165/174 [00:24<00:01,  6.87it/s, loss=0.231, v_num=8]\n",
      "Epoch 3:  97%|█████████▋| 168/174 [00:24<00:00,  6.91it/s, loss=0.231, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 10.90it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 171/174 [00:24<00:00,  6.96it/s, loss=0.231, v_num=8]\n",
      "Epoch 3: 100%|██████████| 174/174 [00:24<00:00,  7.00it/s, loss=0.231, v_num=8]\n",
      "Epoch 4:  78%|███████▊  | 135/174 [00:21<00:06,  6.29it/s, loss=0.211, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 138/174 [00:21<00:05,  6.37it/s, loss=0.211, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.24it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 141/174 [00:21<00:05,  6.43it/s, loss=0.211, v_num=8]\n",
      "Epoch 4:  83%|████████▎ | 144/174 [00:22<00:04,  6.49it/s, loss=0.211, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.29it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 147/174 [00:22<00:04,  6.53it/s, loss=0.211, v_num=8]\n",
      "Epoch 4:  86%|████████▌ | 150/174 [00:22<00:03,  6.59it/s, loss=0.211, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 10.84it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 153/174 [00:23<00:03,  6.64it/s, loss=0.211, v_num=8]\n",
      "Epoch 4:  90%|████████▉ | 156/174 [00:23<00:02,  6.69it/s, loss=0.211, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.01it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 159/174 [00:23<00:02,  6.74it/s, loss=0.211, v_num=8]\n",
      "Epoch 4:  93%|█████████▎| 162/174 [00:23<00:01,  6.79it/s, loss=0.211, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.06it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 165/174 [00:24<00:01,  6.84it/s, loss=0.211, v_num=8]\n",
      "Epoch 4:  97%|█████████▋| 168/174 [00:24<00:00,  6.89it/s, loss=0.211, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.08it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 171/174 [00:24<00:00,  6.93it/s, loss=0.211, v_num=8]\n",
      "Epoch 4: 100%|██████████| 174/174 [00:24<00:00,  6.98it/s, loss=0.211, v_num=8]\n",
      "Epoch 5:  78%|███████▊  | 135/174 [00:21<00:06,  6.30it/s, loss=0.204, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 138/174 [00:21<00:05,  6.38it/s, loss=0.204, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.24it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 141/174 [00:21<00:05,  6.44it/s, loss=0.204, v_num=8]\n",
      "Epoch 5:  83%|████████▎ | 144/174 [00:22<00:04,  6.49it/s, loss=0.204, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.93it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 147/174 [00:22<00:04,  6.55it/s, loss=0.204, v_num=8]\n",
      "Epoch 5:  86%|████████▌ | 150/174 [00:22<00:03,  6.60it/s, loss=0.204, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 10.72it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 153/174 [00:23<00:03,  6.65it/s, loss=0.204, v_num=8]\n",
      "Epoch 5:  90%|████████▉ | 156/174 [00:23<00:02,  6.70it/s, loss=0.204, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 10.97it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████▏| 159/174 [00:23<00:02,  6.75it/s, loss=0.204, v_num=8]\n",
      "Epoch 5:  93%|█████████▎| 162/174 [00:23<00:01,  6.80it/s, loss=0.204, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.02it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 165/174 [00:24<00:01,  6.85it/s, loss=0.204, v_num=8]\n",
      "Epoch 5:  97%|█████████▋| 168/174 [00:24<00:00,  6.90it/s, loss=0.204, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.06it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 171/174 [00:24<00:00,  6.94it/s, loss=0.204, v_num=8]\n",
      "Epoch 5: 100%|██████████| 174/174 [00:24<00:00,  6.99it/s, loss=0.204, v_num=8]\n",
      "Epoch 6:  78%|███████▊  | 135/174 [00:21<00:06,  6.34it/s, loss=0.196, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 138/174 [00:21<00:05,  6.42it/s, loss=0.196, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.25it/s]\u001b[A\n",
      "Epoch 6:  81%|████████  | 141/174 [00:21<00:05,  6.48it/s, loss=0.196, v_num=8]\n",
      "Epoch 6:  83%|████████▎ | 144/174 [00:22<00:04,  6.53it/s, loss=0.196, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.94it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 147/174 [00:22<00:04,  6.59it/s, loss=0.196, v_num=8]\n",
      "Epoch 6:  86%|████████▌ | 150/174 [00:22<00:03,  6.64it/s, loss=0.196, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.05it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 153/174 [00:22<00:03,  6.69it/s, loss=0.196, v_num=8]\n",
      "Epoch 6:  90%|████████▉ | 156/174 [00:23<00:02,  6.75it/s, loss=0.196, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████▏| 159/174 [00:23<00:02,  6.80it/s, loss=0.196, v_num=8]\n",
      "Epoch 6:  93%|█████████▎| 162/174 [00:23<00:01,  6.85it/s, loss=0.196, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.09it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 165/174 [00:23<00:01,  6.89it/s, loss=0.196, v_num=8]\n",
      "Epoch 6:  97%|█████████▋| 168/174 [00:24<00:00,  6.94it/s, loss=0.196, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 171/174 [00:24<00:00,  6.99it/s, loss=0.196, v_num=8]\n",
      "Epoch 6: 100%|██████████| 174/174 [00:24<00:00,  7.03it/s, loss=0.196, v_num=8]\n",
      "Epoch 7:  78%|███████▊  | 135/174 [00:21<00:06,  6.35it/s, loss=0.191, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 138/174 [00:21<00:05,  6.42it/s, loss=0.191, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.25it/s]\u001b[A\n",
      "Epoch 7:  81%|████████  | 141/174 [00:21<00:05,  6.48it/s, loss=0.191, v_num=8]\n",
      "Epoch 7:  83%|████████▎ | 144/174 [00:22<00:04,  6.54it/s, loss=0.191, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.94it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 147/174 [00:22<00:04,  6.59it/s, loss=0.191, v_num=8]\n",
      "Epoch 7:  86%|████████▌ | 150/174 [00:22<00:03,  6.65it/s, loss=0.191, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.05it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 153/174 [00:22<00:03,  6.70it/s, loss=0.191, v_num=8]\n",
      "Epoch 7:  90%|████████▉ | 156/174 [00:23<00:02,  6.75it/s, loss=0.191, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████▏| 159/174 [00:23<00:02,  6.80it/s, loss=0.191, v_num=8]\n",
      "Epoch 7:  93%|█████████▎| 162/174 [00:23<00:01,  6.85it/s, loss=0.191, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 165/174 [00:23<00:01,  6.90it/s, loss=0.191, v_num=8]\n",
      "Epoch 7:  97%|█████████▋| 168/174 [00:24<00:00,  6.94it/s, loss=0.191, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 171/174 [00:24<00:00,  6.99it/s, loss=0.191, v_num=8]\n",
      "Epoch 7: 100%|██████████| 174/174 [00:24<00:00,  7.04it/s, loss=0.191, v_num=8]\n",
      "Epoch 8:  78%|███████▊  | 135/174 [00:21<00:06,  6.33it/s, loss=0.186, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 138/174 [00:21<00:05,  6.41it/s, loss=0.186, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.26it/s]\u001b[A\n",
      "Epoch 8:  81%|████████  | 141/174 [00:21<00:05,  6.47it/s, loss=0.186, v_num=8]\n",
      "Epoch 8:  83%|████████▎ | 144/174 [00:22<00:04,  6.52it/s, loss=0.186, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.94it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 147/174 [00:22<00:04,  6.58it/s, loss=0.186, v_num=8]\n",
      "Epoch 8:  86%|████████▌ | 150/174 [00:22<00:03,  6.63it/s, loss=0.186, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.04it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 153/174 [00:22<00:03,  6.68it/s, loss=0.186, v_num=8]\n",
      "Epoch 8:  90%|████████▉ | 156/174 [00:23<00:02,  6.74it/s, loss=0.186, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████▏| 159/174 [00:23<00:02,  6.79it/s, loss=0.186, v_num=8]\n",
      "Epoch 8:  93%|█████████▎| 162/174 [00:23<00:01,  6.84it/s, loss=0.186, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.09it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 165/174 [00:23<00:01,  6.88it/s, loss=0.186, v_num=8]\n",
      "Epoch 8:  97%|█████████▋| 168/174 [00:24<00:00,  6.93it/s, loss=0.186, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.08it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 171/174 [00:24<00:00,  6.98it/s, loss=0.186, v_num=8]\n",
      "Epoch 8: 100%|██████████| 174/174 [00:24<00:00,  7.02it/s, loss=0.186, v_num=8]\n",
      "Epoch 9:  78%|███████▊  | 135/174 [00:21<00:06,  6.34it/s, loss=0.184, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 138/174 [00:21<00:05,  6.42it/s, loss=0.184, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.27it/s]\u001b[A\n",
      "Epoch 9:  81%|████████  | 141/174 [00:21<00:05,  6.47it/s, loss=0.184, v_num=8]\n",
      "Epoch 9:  83%|████████▎ | 144/174 [00:22<00:04,  6.53it/s, loss=0.184, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.94it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 147/174 [00:22<00:04,  6.59it/s, loss=0.184, v_num=8]\n",
      "Epoch 9:  86%|████████▌ | 150/174 [00:22<00:03,  6.64it/s, loss=0.184, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.06it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 153/174 [00:22<00:03,  6.69it/s, loss=0.184, v_num=8]\n",
      "Epoch 9:  90%|████████▉ | 156/174 [00:23<00:02,  6.75it/s, loss=0.184, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.09it/s]\u001b[A\n",
      "Epoch 9:  91%|█████████▏| 159/174 [00:23<00:02,  6.80it/s, loss=0.184, v_num=8]\n",
      "Epoch 9:  93%|█████████▎| 162/174 [00:23<00:01,  6.84it/s, loss=0.184, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 165/174 [00:23<00:01,  6.89it/s, loss=0.184, v_num=8]\n",
      "Epoch 9:  97%|█████████▋| 168/174 [00:24<00:00,  6.94it/s, loss=0.184, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 171/174 [00:24<00:00,  6.99it/s, loss=0.184, v_num=8]\n",
      "Epoch 9: 100%|██████████| 174/174 [00:24<00:00,  7.03it/s, loss=0.184, v_num=8]\n",
      "Epoch 10:  78%|███████▊  | 135/174 [00:20<00:06,  6.45it/s, loss=0.181, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 138/174 [00:21<00:05,  6.52it/s, loss=0.181, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.25it/s]\u001b[A\n",
      "Epoch 10:  81%|████████  | 141/174 [00:21<00:05,  6.58it/s, loss=0.181, v_num=8]\n",
      "Epoch 10:  83%|████████▎ | 144/174 [00:21<00:04,  6.64it/s, loss=0.181, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.95it/s]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 147/174 [00:21<00:04,  6.69it/s, loss=0.181, v_num=8]\n",
      "Epoch 10:  86%|████████▌ | 150/174 [00:22<00:03,  6.74it/s, loss=0.181, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.07it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 153/174 [00:22<00:03,  6.80it/s, loss=0.181, v_num=8]\n",
      "Epoch 10:  90%|████████▉ | 156/174 [00:22<00:02,  6.85it/s, loss=0.181, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 10:  91%|█████████▏| 159/174 [00:23<00:02,  6.90it/s, loss=0.181, v_num=8]\n",
      "Epoch 10:  93%|█████████▎| 162/174 [00:23<00:01,  6.95it/s, loss=0.181, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.09it/s]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 165/174 [00:23<00:01,  6.99it/s, loss=0.181, v_num=8]\n",
      "Epoch 10:  97%|█████████▋| 168/174 [00:23<00:00,  7.04it/s, loss=0.181, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.09it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 171/174 [00:24<00:00,  7.09it/s, loss=0.181, v_num=8]\n",
      "Epoch 10: 100%|██████████| 174/174 [00:24<00:00,  7.13it/s, loss=0.181, v_num=8]\n",
      "Epoch 11:  78%|███████▊  | 135/174 [00:21<00:06,  6.30it/s, loss=0.175, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  79%|███████▉  | 138/174 [00:21<00:05,  6.37it/s, loss=0.175, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.24it/s]\u001b[A\n",
      "Epoch 11:  81%|████████  | 141/174 [00:21<00:05,  6.43it/s, loss=0.175, v_num=8]\n",
      "Epoch 11:  83%|████████▎ | 144/174 [00:22<00:04,  6.41it/s, loss=0.175, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:01<00:04,  7.03it/s]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 147/174 [00:22<00:04,  6.47it/s, loss=0.175, v_num=8]\n",
      "Epoch 11:  86%|████████▌ | 150/174 [00:23<00:03,  6.52it/s, loss=0.175, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02,  9.48it/s]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 153/174 [00:23<00:03,  6.57it/s, loss=0.175, v_num=8]\n",
      "Epoch 11:  90%|████████▉ | 156/174 [00:23<00:02,  6.63it/s, loss=0.175, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:02<00:01, 10.51it/s]\u001b[A\n",
      "Epoch 11:  91%|█████████▏| 159/174 [00:23<00:02,  6.68it/s, loss=0.175, v_num=8]\n",
      "Epoch 11:  93%|█████████▎| 162/174 [00:24<00:01,  6.73it/s, loss=0.175, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 10.89it/s]\u001b[A\n",
      "Epoch 11:  95%|█████████▍| 165/174 [00:24<00:01,  6.77it/s, loss=0.175, v_num=8]\n",
      "Epoch 11:  97%|█████████▋| 168/174 [00:24<00:00,  6.82it/s, loss=0.175, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.02it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 171/174 [00:24<00:00,  6.87it/s, loss=0.175, v_num=8]\n",
      "Epoch 11: 100%|██████████| 174/174 [00:25<00:00,  6.91it/s, loss=0.175, v_num=8]\n",
      "Epoch 12:  78%|███████▊  | 135/174 [00:21<00:06,  6.33it/s, loss=0.172, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  79%|███████▉  | 138/174 [00:21<00:05,  6.41it/s, loss=0.172, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.24it/s]\u001b[A\n",
      "Epoch 12:  81%|████████  | 141/174 [00:21<00:05,  6.46it/s, loss=0.172, v_num=8]\n",
      "Epoch 12:  83%|████████▎ | 144/174 [00:22<00:04,  6.52it/s, loss=0.172, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.93it/s]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 147/174 [00:22<00:04,  6.58it/s, loss=0.172, v_num=8]\n",
      "Epoch 12:  86%|████████▌ | 150/174 [00:22<00:03,  6.63it/s, loss=0.172, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.04it/s]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 153/174 [00:22<00:03,  6.68it/s, loss=0.172, v_num=8]\n",
      "Epoch 12:  90%|████████▉ | 156/174 [00:23<00:02,  6.74it/s, loss=0.172, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.07it/s]\u001b[A\n",
      "Epoch 12:  91%|█████████▏| 159/174 [00:23<00:02,  6.78it/s, loss=0.172, v_num=8]\n",
      "Epoch 12:  93%|█████████▎| 162/174 [00:23<00:01,  6.83it/s, loss=0.172, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.10it/s]\u001b[A\n",
      "Epoch 12:  95%|█████████▍| 165/174 [00:23<00:01,  6.88it/s, loss=0.172, v_num=8]\n",
      "Epoch 12:  97%|█████████▋| 168/174 [00:24<00:00,  6.93it/s, loss=0.172, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 171/174 [00:24<00:00,  6.98it/s, loss=0.172, v_num=8]\n",
      "Epoch 12: 100%|██████████| 174/174 [00:24<00:00,  7.02it/s, loss=0.172, v_num=8]\n",
      "Epoch 13:  78%|███████▊  | 135/174 [00:21<00:06,  6.34it/s, loss=0.171, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  79%|███████▉  | 138/174 [00:21<00:05,  6.41it/s, loss=0.171, v_num=8]\n",
      "Validating:   8%|▊         | 3/39 [00:00<00:03, 10.26it/s]\u001b[A\n",
      "Epoch 13:  81%|████████  | 141/174 [00:21<00:05,  6.47it/s, loss=0.171, v_num=8]\n",
      "Epoch 13:  83%|████████▎ | 144/174 [00:22<00:04,  6.53it/s, loss=0.171, v_num=8]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:02, 10.93it/s]\u001b[A\n",
      "Epoch 13:  84%|████████▍ | 147/174 [00:22<00:04,  6.58it/s, loss=0.171, v_num=8]\n",
      "Epoch 13:  86%|████████▌ | 150/174 [00:22<00:03,  6.64it/s, loss=0.171, v_num=8]\n",
      "Validating:  38%|███▊      | 15/39 [00:01<00:02, 11.04it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 153/174 [00:22<00:03,  6.69it/s, loss=0.171, v_num=8]\n",
      "Epoch 13:  90%|████████▉ | 156/174 [00:23<00:02,  6.74it/s, loss=0.171, v_num=8]\n",
      "Validating:  54%|█████▍    | 21/39 [00:01<00:01, 11.08it/s]\u001b[A\n",
      "Epoch 13:  91%|█████████▏| 159/174 [00:23<00:02,  6.79it/s, loss=0.171, v_num=8]\n",
      "Epoch 13:  93%|█████████▎| 162/174 [00:23<00:01,  6.84it/s, loss=0.171, v_num=8]\n",
      "Validating:  69%|██████▉   | 27/39 [00:02<00:01, 11.10it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▍| 165/174 [00:23<00:01,  6.89it/s, loss=0.171, v_num=8]\n",
      "Epoch 13:  97%|█████████▋| 168/174 [00:24<00:00,  6.94it/s, loss=0.171, v_num=8]\n",
      "Validating:  85%|████████▍ | 33/39 [00:03<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 171/174 [00:24<00:00,  6.98it/s, loss=0.171, v_num=8]\n",
      "Epoch 13: 100%|██████████| 174/174 [00:24<00:00,  7.04it/s, loss=0.171, v_num=8]\n",
      "Epoch 13: 100%|██████████| 174/174 [00:26<00:00,  6.64it/s, loss=0.171, v_num=8]\n",
      "Epoch 14:  29%|██▊       | 50/174 [00:08<00:19,  6.24it/s, loss=0.166, v_num=8] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  29%|██▊       | 50/174 [00:26<01:06,  1.85it/s, loss=0.166, v_num=8]"
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "autoencoder = CNN_UNET_4L()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN 10 MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "\n",
    "    if cnn_type == '4L':\n",
    "        autoencoder = CNN_UNET_4L()\n",
    "        filename_chkpt = 'CNN_UNET_4L_{0}'.format(i)\n",
    "    elif cnn_type =='surf':\n",
    "\n",
    "        autoencoder = CNN_UNET_SURF()\n",
    "        filename_chkpt = 'CNN_UNET_SURF_{0}'.format(i)\n",
    "        \n",
    "    filename_chkpt = 'CNN_UNET_SURFACE_{0}'.format(i)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='loss_no_filter',\n",
    "                                              dirpath= dirSAVE,\n",
    "                                              filename= filename_chkpt,\n",
    "                                              save_top_k=1,\n",
    "                                              mode='min')\n",
    "\n",
    "    dirLOG = './logs/supermodel/{0}'.format(filename_chkpt)\n",
    "\n",
    "\n",
    "    # TRAINNING \n",
    "    trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "    trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN using 4 vertical levels\n",
    "\n",
    "alpha1 = 0.8\n",
    "alpha2 = 1-0.8\n",
    "nb_dx = 100\n",
    "\n",
    "class CNN_UNET_4L(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(    \n",
    "        nn.Conv2d(76, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(64)\n",
    "             )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(    \n",
    "        nn.Conv2d(64, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.Conv2d(128, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(128)\n",
    "             )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(    \n",
    "        nn.Conv2d(128, 256, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.Conv2d(256, 256, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(256)\n",
    "             )\n",
    "        \n",
    "        self.conv_up1 = nn.Sequential(    \n",
    "        nn.Conv2d(128, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 8, kernel_size = 3, padding = 1, bias=False)\n",
    "             )\n",
    "        \n",
    "        self.conv_up2 = nn.Sequential(    \n",
    "        nn.Conv2d(256, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.Conv2d(128, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(128)\n",
    "             )\n",
    "        \n",
    "        self.convTrans3 = nn.ConvTranspose2d(256,128,kernel_size = 2,padding = 0,stride=2)\n",
    "        self.convTrans2 = nn.ConvTranspose2d(128,64,kernel_size = 2,padding = 0,stride=2)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.flatten = nn.Flatten(start_dim=2, end_dim=- 1)\n",
    "        self.maxpool2d = nn.MaxPool2d(2)\n",
    "        self.avgpool2d = nn.AvgPool2d(2)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, z, y_filter,y):\n",
    "        \n",
    "        y_pred = torch.zeros(y.shape).to('cuda')\n",
    "        #print(y_pred.device)\n",
    "        y_pred[:,:,49:51,49:51] = 0.25 # Initialisation of y_pred\n",
    "        #print(y_pred.device)\n",
    "        #print(z.device)\n",
    "\n",
    "        y1 = torch.cat((z,y_pred),dim=1) \n",
    "        y1 = self.conv1(y1)\n",
    "        y2 = self.maxpool2d(y1)\n",
    "        y2 = self.conv2(y2)\n",
    "        y3 = self.maxpool2d(y2)\n",
    "        y3 = self.conv3(y3)\n",
    "        \n",
    "        y3 = self.convTrans3(y3)\n",
    "        y3 = torch.cat((y2,y3),dim=1)\n",
    "        y2 = self.conv_up2(y3)\n",
    "        \n",
    "        y2 = self.convTrans2(y2)\n",
    "        y2 = torch.cat((y1,y2),dim=1)\n",
    "        y1 = self.conv_up1(y2)\n",
    "        \n",
    "        y_hat = self.flatten(y1)\n",
    "        y_hat = self.relu(y_hat)\n",
    "        y_hat = self.softmax(torch.log(y_hat+1e-10)) \n",
    "        y_hat = y_hat.view(y_hat.shape[0],8,nb_dx,nb_dx)\n",
    "        \n",
    "        return y_hat \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = 0.001\n",
    "        optimizer = optim.Adam(self.parameters(),lr= lr, betas=(0.5, 0.999),weight_decay=0)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        z, y_f, y = batch\n",
    "        y_hat = self(z,y_f,y)\n",
    "        loss = 0\n",
    "\n",
    "        \n",
    "        for i in range(0,8):\n",
    "            loss = loss + alpha1*Bhatta_loss(y_hat[:,i,:,:], y_f[:,i,:,:]) + alpha2*Bhatta_loss(y_hat[:,i,:,:], y[:,i,:,:])\n",
    "            \n",
    "        loss = loss / 8\n",
    "        \n",
    "        loss_filter_200m = Bhatta_loss(y_hat[:,-1,:,:], y_f[:,-1,:,:])\n",
    "        \n",
    "        self.log(\"loss_train\", loss, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_filter_200m_train\", loss, on_epoch=True, on_step = True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        z, y_f, y = batch\n",
    "        y_hat = self(z,y_f,y)\n",
    "        \n",
    "        loss_filter = 0\n",
    "        loss_no_filter = 0\n",
    "\n",
    "        for i in range(0,8):\n",
    "            loss_filter = loss_filter + Bhatta_loss(y_hat[:,i,:,:], y_f[:,i,:,:])\n",
    "            loss_no_filter = loss_no_filter + Bhatta_loss(y_hat[:,i,:,:], y[:,i,:,:])\n",
    "            \n",
    "        loss_filter = loss_filter / 8\n",
    "        loss_no_filter = loss_no_filter / 8\n",
    "        \n",
    "        loss_filter_200m = Bhatta_loss(y_hat[:,-1,:,:], y_f[:,-1,:,:])\n",
    "        \n",
    "        self.log(\"loss_filter_validation\", loss_filter, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_no_filter_validation\", loss_no_filter, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_filter_200m_validation\", loss_filter_200m, on_epoch=True, on_step = True)\n",
    "        \n",
    "        return loss_no_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-dcb0ca9d-55d4-28a2-1aa7-2638e1a18e28]\n",
      "\n",
      "   | Name       | Type            | Params\n",
      "------------------------------------------------\n",
      "0  | conv1      | Sequential      | 80.9 K\n",
      "1  | conv2      | Sequential      | 221 K \n",
      "2  | conv3      | Sequential      | 885 K \n",
      "3  | conv_up1   | Sequential      | 115 K \n",
      "4  | conv_up2   | Sequential      | 442 K \n",
      "5  | convTrans3 | ConvTranspose2d | 131 K \n",
      "6  | convTrans2 | ConvTranspose2d | 32.8 K\n",
      "7  | softmax    | Softmax         | 0     \n",
      "8  | flatten    | Flatten         | 0     \n",
      "9  | maxpool2d  | MaxPool2d       | 0     \n",
      "10 | avgpool2d  | AvgPool2d       | 0     \n",
      "11 | relu       | ReLU            | 0     \n",
      "------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.643     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 30/310 [00:09<01:27,  3.21it/s, loss=0.65, v_num=3] "
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "autoencoder = CNN_UNET_4L()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load packages\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import sys\n",
    "import netCDF4 as nc4\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "sys.path.append(\"/home2/datahome/tpicard/python/Python_Modules_p3_pyticles/\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def read_input():\n",
    "    nc_name = 'Inputs_vertical_levels_4layers_{0}_sorted.nc'.format(nb_dx)\n",
    "    nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "    inputs_test = np.asfortranarray(nc.variables['inputs_test'])\n",
    "    inputs_train = np.asfortranarray(nc.variables['inputs_train'])\n",
    "    nc.close()\n",
    "    return(inputs_test,inputs_train)\n",
    "\n",
    "def read_output():\n",
    "    \n",
    "    if filt =='L50':\n",
    "        nc_name = 'pdf_4levels_{0}_filter_L50_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test_filter'])\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train_filter'])\n",
    "        \n",
    "    elif filt =='L5':\n",
    "        nc_name = 'pdf_vertical_levels_{0}_filter_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test_filter'])\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train_filter'])\n",
    "        \n",
    "    else :\n",
    "        nc_name = 'pdf_vertical_levels_4layers{0}_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test'])*((800/nb_dx)**2)\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train'])*((800/nb_dx)**2)\n",
    "        nc.close()\n",
    "        \n",
    "    return(pdf_test,pdf_train)\n",
    "\n",
    "class Pdf_Image_DataSet(Dataset):\n",
    "    def __init__(self,images, pdf_f,pdf_nf,transform=None):\n",
    "        \n",
    "        self.pdf_f = pdf_f\n",
    "        self.pdf_nf = pdf_nf\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.pdf_f.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # select coordinates\n",
    "        pdf_f_sample = self.pdf_f[idx,1:,0,:,:]\n",
    "        pdf_nf_sample = self.pdf_nf[idx,1:,0,:,:]\n",
    "        image_sample = self.images[idx,:,:,:]\n",
    "        \n",
    "        if self.transform:\n",
    "            pdf_f_sample = self.transform(pdf_f_sample)\n",
    "            pdf_nf_sample = self.transform(pdf_nf_sample)\n",
    "            image_sample = self.transform(image_sample)\n",
    "            \n",
    "        return image_sample, pdf_f_sample, pdf_nf_sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        return torch.FloatTensor(sample)\n",
    "\n",
    "#GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#READ DATA Filter\n",
    "filt = 'L50'\n",
    "(pdf_test_filter,pdf_train_filter) = read_output()\n",
    "(inputs_test,inputs_train) = read_input()\n",
    "\n",
    "#READ DATA No Filter\n",
    "filt = 'No'\n",
    "(pdf_test_no_f,pdf_train_no_f) = read_output()\n",
    "\n",
    "# MEAN and STD for each channel\n",
    "list_mean_train = []\n",
    "list_std_train = []\n",
    "\n",
    "\n",
    "for i in range(inputs_train.shape[1]):\n",
    "    list_mean_train.append(np.mean(inputs_train[:,i,:,:]))\n",
    "    list_std_train.append(np.std(inputs_train[:,i,:,:]))\n",
    "\n",
    "\n",
    "# Normalization of inputs\n",
    "Normalize = transforms.Normalize(list_mean_train, list_std_train)\n",
    "inputs_test = Normalize(torch.tensor(inputs_test))\n",
    "inputs_train = Normalize(torch.tensor(inputs_train))\n",
    "\n",
    "i = 0\n",
    "\n",
    "#inputs_test_1l = np.concatenate((inputs_test[:,4*i:4*i+4,:,:],inputs_test[:,4*i+16:4*i+4+16,:,:],inputs_test[:,4*i+32:4*i+4+32,:,:],inputs_test[:,4*i+48:4*i+4+48,:,:],inputs_test[:,64:,:,:]),axis=1)\n",
    "#inputs_train_1l = np.concatenate((inputs_train[:,4*i:4*i+4,:,:],inputs_train[:,4*i+16:4*i+4+16,:,:],inputs_train[:,4*i+32:4*i+4+32,:,:],inputs_train[:,4*i+48:4*i+4+48,:,:],inputs_train[:,64:,:,:]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## reduce size dataset\n",
    "train_set = Pdf_Image_DataSet(inputs_train,pdf_train_filter,pdf_train_no_f,transform= ToTensor())\n",
    "train_loader_old = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=False)\n",
    "\n",
    "test_set = Pdf_Image_DataSet(inputs_test,pdf_test_filter,pdf_test_no_f,transform= ToTensor())\n",
    "test_loader_old = DataLoader(test_set, batch_size=batch_size, num_workers = 0, shuffle = False, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4900, 68, 100, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900, 9, 1, 100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_train_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-739dfd1b-f418-cc5b-11cf-7fb8737907b5]\n",
      "\n",
      "   | Name       | Type            | Params\n",
      "------------------------------------------------\n",
      "0  | conv1      | Sequential      | 80.9 K\n",
      "1  | conv2      | Sequential      | 221 K \n",
      "2  | conv3      | Sequential      | 885 K \n",
      "3  | conv_up1   | Sequential      | 115 K \n",
      "4  | conv_up2   | Sequential      | 442 K \n",
      "5  | convTrans3 | ConvTranspose2d | 131 K \n",
      "6  | convTrans2 | ConvTranspose2d | 32.8 K\n",
      "7  | softmax    | Softmax         | 0     \n",
      "8  | flatten    | Flatten         | 0     \n",
      "9  | maxpool2d  | MaxPool2d       | 0     \n",
      "10 | avgpool2d  | AvgPool2d       | 0     \n",
      "11 | relu       | ReLU            | 0     \n",
      "------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.643     Total estimated model params size (MB)\n",
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home2/datahome/tpicard/PhD_MOMOPAR/TRAIN_AND_VALIDATION_CNN/Saved_model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████ | 154/170 [00:35<00:03,  4.29it/s, loss=0.447, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 156/170 [00:36<00:03,  4.32it/s, loss=0.447, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.00it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 159/170 [00:36<00:02,  4.36it/s, loss=0.447, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.48it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 162/170 [00:36<00:01,  4.40it/s, loss=0.447, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 165/170 [00:37<00:01,  4.44it/s, loss=0.447, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.47it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.49it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 168/170 [00:37<00:00,  4.48it/s, loss=0.447, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.24it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 170/170 [00:37<00:00,  4.50it/s, loss=0.447, v_num=6]\n",
      "Epoch 1:  91%|█████████ | 154/170 [00:35<00:03,  4.31it/s, loss=0.342, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 156/170 [00:35<00:03,  4.35it/s, loss=0.342, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.02it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 159/170 [00:36<00:02,  4.39it/s, loss=0.342, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.54it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 162/170 [00:36<00:01,  4.43it/s, loss=0.342, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.31it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 165/170 [00:36<00:01,  4.47it/s, loss=0.342, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.46it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.36it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 168/170 [00:37<00:00,  4.51it/s, loss=0.342, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 170/170 [00:37<00:00,  4.53it/s, loss=0.342, v_num=6]\n",
      "Epoch 2:  91%|█████████ | 154/170 [00:36<00:03,  4.27it/s, loss=0.254, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 156/170 [00:36<00:03,  4.31it/s, loss=0.254, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.03it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.99it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 159/170 [00:36<00:02,  4.35it/s, loss=0.254, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.55it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 162/170 [00:36<00:01,  4.39it/s, loss=0.254, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.30it/s]\u001b[A\n",
      "Validating:  56%|█████▋    | 9/16 [00:01<00:00,  8.54it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 165/170 [00:37<00:01,  4.43it/s, loss=0.254, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.29it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.40it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 168/170 [00:37<00:00,  4.47it/s, loss=0.254, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.31it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 170/170 [00:37<00:00,  4.49it/s, loss=0.254, v_num=6]\n",
      "Epoch 3:  21%|██        | 36/170 [00:08<00:31,  4.31it/s, loss=0.247, v_num=6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  21%|██        | 36/170 [00:25<01:35,  1.40it/s, loss=0.247, v_num=6]"
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "autoencoder = CNN_UNET_4L()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader_old,val_dataloaders=test_loader_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croco",
   "language": "python",
   "name": "croco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
