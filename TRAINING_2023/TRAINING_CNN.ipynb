{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import sys\n",
    "import netCDF4 as nc4\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "sys.path.append(\"/home2/datahome/tpicard/python/Python_Modules_p3_pyticles/\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from CNN_tools import *\n",
    "from CNN_UNET import *\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from DATALOADER import Pdf_Image_DataSet, Pdf_Image_DataSet_image_process\n",
    "from variables import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN TYPE ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save direction and type of cnn\n",
    "kernel_size=5\n",
    "padding=2\n",
    "bias=False\n",
    "p_dropout=0\n",
    "nlayer0=64\n",
    "\n",
    "cnn_type = 'surf_1step'\n",
    "\n",
    "if cnn_type == '4L':\n",
    "    autoencoder = CNN_UNET_4L()\n",
    "    filename_chkpt = 'CNN_UNET_4L_2.0'\n",
    "elif cnn_type =='surf':\n",
    "    \n",
    "    autoencoder = CNN_UNET_SURF()\n",
    "    filename_chkpt = 'CNN_UNET_SURF'\n",
    "    \n",
    "elif cnn_type =='surf_1step':\n",
    "    \n",
    "    autoencoder = CNN_UNET_SURF_1step()\n",
    "    filename_chkpt = 'CNN_UNET_SURF_1STEP'\n",
    "    \n",
    "elif cnn_type =='generic':\n",
    "    \n",
    "    autoencoder = CNN_UNET_generic(kernel_size,padding,bias,p_dropout,nlayer0)\n",
    "    filename_chkpt = 'CNN_UNET_k{0}_p{1}_b{2}_d{3}_nl{4}'.format(kernel_size,padding,bias,p_dropout,nlayer0)\n",
    "    \n",
    "dirSAVE = './Saved_model'\n",
    "checkpoint_callback = ModelCheckpoint(monitor='loss_filter_200m_validation',\n",
    "                                              dirpath= dirSAVE,\n",
    "                                              filename= filename_chkpt + '-{epoch:02d}-{loss_filter_200m_validation:.2f}',\n",
    "                                              save_top_k=2,\n",
    "                                              mode='min')\n",
    "dirLOG = './logs/{0}/'.format(filename_chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training surface data ...\n",
      "Done\n",
      "Loading validation surface data ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATA ####\n",
    "\n",
    "#image_train = load_images_train('half')\n",
    "image_train = load_images_train_surface('half')\n",
    "Normalize = transforms.Normalize(list_mean_train_surface, list_std_train_surface)\n",
    "image_train = Normalize(torch.tensor(image_train))\n",
    "\n",
    "image_eval = load_images_validation_surface()\n",
    "image_eval = Normalize(torch.tensor(image_eval))\n",
    "#image_norm_train = load_images_train()\n",
    "\n",
    "'''\n",
    "# Normalization of inputs\n",
    "Normalize = transforms.Normalize(list_mean_train, list_std_train)\n",
    "image_train = Normalize(torch.tensor(image_train))\n",
    "\n",
    "image_eval = load_images_validation()\n",
    "image_eval = Normalize(torch.tensor(image_eval))\n",
    "'''\n",
    "\n",
    "pdf_train = load_pdf_train()\n",
    "pdf_filter_train = load_pdf_filter_train()\n",
    "\n",
    "pdf_train = load_pdf_train()\n",
    "pdf_filter_train = load_pdf_filter_train()\n",
    "\n",
    "pdf_train = np.transpose(pdf_train,(0,2,1,3,4))\n",
    "pdf_train = pdf_train.reshape(pdf_train.shape[0]*pdf_train.shape[1],8,100,100)\n",
    "pdf_train = pdf_train[::2]\n",
    "\n",
    "pdf_filter_train = np.transpose(pdf_filter_train,(0,2,1,3,4))\n",
    "pdf_filter_train = pdf_filter_train.reshape(pdf_filter_train.shape[0]*pdf_filter_train.shape[1],8,100,100)\n",
    "pdf_filter_train = pdf_filter_train[::2]\n",
    "\n",
    "#image_norm_eval = load_image_processed('validation')\n",
    "#image_eval = load_images_validation()\n",
    "\n",
    "\n",
    "pdf_eval = load_pdf_validation()\n",
    "pdf_filter_eval = load_pdf_filter_validation()\n",
    "\n",
    "\n",
    "pdf_eval = np.transpose(pdf_eval,(0,2,1,3,4))\n",
    "pdf_eval = pdf_eval.reshape(pdf_eval.shape[0]*pdf_eval.shape[1],8,100,100)\n",
    "\n",
    "pdf_filter_eval = np.transpose(pdf_filter_eval,(0,2,1,3,4))\n",
    "pdf_filter_eval = pdf_filter_eval.reshape(pdf_filter_eval.shape[0]*pdf_filter_eval.shape[1],8,100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAINING AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Pdf_Image_DataSet(image_train,pdf_train,pdf_filter_train,transform= ToTensor())\n",
    "eval_set = Pdf_Image_DataSet(image_eval,pdf_eval,pdf_filter_eval,transform= ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=False)\n",
    "eval_loader = DataLoader(eval_set, batch_size=batch_size, num_workers = 0, shuffle = False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-312ca2e1-f08f-4fae-19ab-55f09735c2dc]\n",
      "Missing logger folder: logs/CNN_UNET_SURF_1STEP/lightning_logs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | conv1     | Sequential | 90.2 K\n",
      "1 | conv_up1  | Sequential | 115 K \n",
      "2 | softmax   | Softmax    | 0     \n",
      "3 | flatten   | Flatten    | 0     \n",
      "4 | maxpool2d | MaxPool2d  | 0     \n",
      "5 | avgpool2d | AvgPool2d  | 0     \n",
      "6 | relu      | ReLU       | 0     \n",
      "-----------------------------------------\n",
      "205 K     Trainable params\n",
      "0         Non-trainable params\n",
      "205 K     Total params\n",
      "0.823     Total estimated model params size (MB)\n",
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home2/datahome/tpicard/PhD_MOMOPAR/TRAIN_AND_VALIDATION_CNN/Saved_model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 135/174 [00:09<00:02, 14.66it/s, loss=0.568, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 138/174 [00:09<00:02, 14.86it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 142/174 [00:09<00:02, 15.09it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  84%|████████▍ | 146/174 [00:09<00:01, 15.31it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 150/174 [00:09<00:01, 15.53it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 154/174 [00:09<00:01, 15.74it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 158/174 [00:09<00:01, 15.94it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 162/174 [00:10<00:00, 16.14it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 166/174 [00:10<00:00, 16.33it/s, loss=0.568, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 170/174 [00:10<00:00, 16.52it/s, loss=0.568, v_num=0]\n",
      "Epoch 0: 100%|██████████| 174/174 [00:10<00:00, 16.71it/s, loss=0.568, v_num=0]\n",
      "Epoch 0: 100%|██████████| 174/174 [00:10<00:00, 16.68it/s, loss=0.568, v_num=0]\n",
      "Epoch 1:  78%|███████▊  | 136/174 [00:09<00:02, 14.44it/s, loss=0.553, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 140/174 [00:09<00:02, 14.64it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 144/174 [00:09<00:02, 14.86it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  85%|████████▌ | 148/174 [00:09<00:01, 15.08it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  87%|████████▋ | 152/174 [00:09<00:01, 15.29it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  90%|████████▉ | 156/174 [00:10<00:01, 15.49it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  92%|█████████▏| 160/174 [00:10<00:00, 15.69it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  94%|█████████▍| 164/174 [00:10<00:00, 15.89it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  97%|█████████▋| 168/174 [00:10<00:00, 16.08it/s, loss=0.553, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 172/174 [00:10<00:00, 16.27it/s, loss=0.553, v_num=0]\n",
      "Epoch 1: 100%|██████████| 174/174 [00:10<00:00, 16.34it/s, loss=0.553, v_num=0]\n",
      "Epoch 2:  78%|███████▊  | 136/174 [00:09<00:02, 14.28it/s, loss=0.541, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 140/174 [00:09<00:02, 14.47it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  83%|████████▎ | 144/174 [00:09<00:02, 14.70it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  85%|████████▌ | 148/174 [00:09<00:01, 14.92it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  87%|████████▋ | 152/174 [00:10<00:01, 15.13it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  90%|████████▉ | 156/174 [00:10<00:01, 15.34it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  92%|█████████▏| 160/174 [00:10<00:00, 15.54it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  94%|█████████▍| 164/174 [00:10<00:00, 15.74it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  97%|█████████▋| 168/174 [00:10<00:00, 15.94it/s, loss=0.541, v_num=0]\n",
      "Epoch 2:  99%|█████████▉| 172/174 [00:10<00:00, 16.13it/s, loss=0.541, v_num=0]\n",
      "Epoch 2: 100%|██████████| 174/174 [00:10<00:00, 16.20it/s, loss=0.541, v_num=0]\n",
      "Epoch 3:  78%|███████▊  | 136/174 [00:09<00:02, 14.37it/s, loss=0.542, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 140/174 [00:09<00:02, 14.58it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  83%|████████▎ | 144/174 [00:09<00:02, 14.80it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  85%|████████▌ | 148/174 [00:09<00:01, 15.02it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  87%|████████▋ | 152/174 [00:09<00:01, 15.24it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  90%|████████▉ | 156/174 [00:10<00:01, 15.45it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  92%|█████████▏| 160/174 [00:10<00:00, 15.65it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  94%|█████████▍| 164/174 [00:10<00:00, 15.84it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  97%|█████████▋| 168/174 [00:10<00:00, 16.04it/s, loss=0.542, v_num=0]\n",
      "Epoch 3:  99%|█████████▉| 172/174 [00:10<00:00, 16.23it/s, loss=0.542, v_num=0]\n",
      "Epoch 3: 100%|██████████| 174/174 [00:10<00:00, 16.30it/s, loss=0.542, v_num=0]\n",
      "Epoch 4:  78%|███████▊  | 136/174 [00:09<00:02, 14.81it/s, loss=0.516, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 140/174 [00:09<00:02, 15.01it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  83%|████████▎ | 144/174 [00:09<00:01, 15.24it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  85%|████████▌ | 148/174 [00:09<00:01, 15.46it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  87%|████████▋ | 152/174 [00:09<00:01, 15.67it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  90%|████████▉ | 156/174 [00:09<00:01, 15.88it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  92%|█████████▏| 160/174 [00:09<00:00, 16.07it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  94%|█████████▍| 164/174 [00:10<00:00, 16.26it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  97%|█████████▋| 168/174 [00:10<00:00, 16.45it/s, loss=0.516, v_num=0]\n",
      "Epoch 4:  99%|█████████▉| 172/174 [00:10<00:00, 16.62it/s, loss=0.516, v_num=0]\n",
      "Epoch 4: 100%|██████████| 174/174 [00:10<00:00, 16.70it/s, loss=0.516, v_num=0]\n",
      "Epoch 5:  78%|███████▊  | 136/174 [00:09<00:02, 14.83it/s, loss=0.518, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  83%|████████▎ | 144/174 [00:09<00:01, 15.25it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  85%|████████▌ | 148/174 [00:09<00:01, 15.47it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  87%|████████▋ | 152/174 [00:09<00:01, 15.68it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  90%|████████▉ | 156/174 [00:09<00:01, 15.89it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  92%|█████████▏| 160/174 [00:09<00:00, 16.08it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  94%|█████████▍| 164/174 [00:10<00:00, 16.28it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  97%|█████████▋| 168/174 [00:10<00:00, 16.47it/s, loss=0.518, v_num=0]\n",
      "Epoch 5:  99%|█████████▉| 172/174 [00:10<00:00, 16.66it/s, loss=0.518, v_num=0]\n",
      "Epoch 5: 100%|██████████| 174/174 [00:10<00:00, 16.73it/s, loss=0.518, v_num=0]\n",
      "Epoch 6:  78%|███████▊  | 136/174 [00:09<00:02, 14.90it/s, loss=0.512, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 140/174 [00:09<00:02, 15.09it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  83%|████████▎ | 144/174 [00:09<00:01, 15.32it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  85%|████████▌ | 148/174 [00:09<00:01, 15.53it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  87%|████████▋ | 152/174 [00:09<00:01, 15.75it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  90%|████████▉ | 156/174 [00:09<00:01, 15.96it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  92%|█████████▏| 160/174 [00:09<00:00, 16.16it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  94%|█████████▍| 164/174 [00:10<00:00, 16.36it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  97%|█████████▋| 168/174 [00:10<00:00, 16.56it/s, loss=0.512, v_num=0]\n",
      "Epoch 6:  99%|█████████▉| 172/174 [00:10<00:00, 16.75it/s, loss=0.512, v_num=0]\n",
      "Epoch 6: 100%|██████████| 174/174 [00:10<00:00, 16.82it/s, loss=0.512, v_num=0]\n",
      "Epoch 7:  78%|███████▊  | 136/174 [00:09<00:02, 14.81it/s, loss=0.509, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  83%|████████▎ | 144/174 [00:09<00:01, 15.24it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  85%|████████▌ | 148/174 [00:09<00:01, 15.46it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  87%|████████▋ | 152/174 [00:09<00:01, 15.67it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  90%|████████▉ | 156/174 [00:09<00:01, 15.88it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  92%|█████████▏| 160/174 [00:09<00:00, 16.09it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  94%|█████████▍| 164/174 [00:10<00:00, 16.28it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  97%|█████████▋| 168/174 [00:10<00:00, 16.47it/s, loss=0.509, v_num=0]\n",
      "Epoch 7:  99%|█████████▉| 172/174 [00:10<00:00, 16.65it/s, loss=0.509, v_num=0]\n",
      "Epoch 7: 100%|██████████| 174/174 [00:10<00:00, 16.73it/s, loss=0.509, v_num=0]\n",
      "Epoch 8:  78%|███████▊  | 136/174 [00:09<00:02, 14.85it/s, loss=0.496, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|████████  | 140/174 [00:09<00:02, 15.06it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  83%|████████▎ | 144/174 [00:09<00:01, 15.28it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  85%|████████▌ | 148/174 [00:09<00:01, 15.50it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  87%|████████▋ | 152/174 [00:09<00:01, 15.72it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  90%|████████▉ | 156/174 [00:09<00:01, 15.93it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  92%|█████████▏| 160/174 [00:09<00:00, 16.13it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  94%|█████████▍| 164/174 [00:10<00:00, 16.33it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  97%|█████████▋| 168/174 [00:10<00:00, 16.52it/s, loss=0.496, v_num=0]\n",
      "Epoch 8:  99%|█████████▉| 172/174 [00:10<00:00, 16.71it/s, loss=0.496, v_num=0]\n",
      "Epoch 8: 100%|██████████| 174/174 [00:10<00:00, 16.78it/s, loss=0.496, v_num=0]\n",
      "Epoch 9:  78%|███████▊  | 136/174 [00:09<00:02, 14.88it/s, loss=0.493, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|████████  | 140/174 [00:09<00:02, 15.10it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  83%|████████▎ | 144/174 [00:09<00:01, 15.32it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  85%|████████▌ | 148/174 [00:09<00:01, 15.54it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  87%|████████▋ | 152/174 [00:09<00:01, 15.76it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  90%|████████▉ | 156/174 [00:09<00:01, 15.96it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  92%|█████████▏| 160/174 [00:09<00:00, 16.16it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  94%|█████████▍| 164/174 [00:10<00:00, 16.36it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  97%|█████████▋| 168/174 [00:10<00:00, 16.56it/s, loss=0.493, v_num=0]\n",
      "Epoch 9:  99%|█████████▉| 172/174 [00:10<00:00, 16.74it/s, loss=0.493, v_num=0]\n",
      "Epoch 9: 100%|██████████| 174/174 [00:10<00:00, 16.82it/s, loss=0.493, v_num=0]\n",
      "Epoch 10:  78%|███████▊  | 136/174 [00:09<00:02, 14.77it/s, loss=0.487, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|████████  | 140/174 [00:09<00:02, 14.99it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  83%|████████▎ | 144/174 [00:09<00:01, 15.21it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  85%|████████▌ | 148/174 [00:09<00:01, 15.43it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  87%|████████▋ | 152/174 [00:09<00:01, 15.64it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  90%|████████▉ | 156/174 [00:09<00:01, 15.84it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  92%|█████████▏| 160/174 [00:09<00:00, 16.04it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  94%|█████████▍| 164/174 [00:10<00:00, 16.24it/s, loss=0.487, v_num=0]\n",
      "Epoch 10:  97%|█████████▋| 168/174 [00:10<00:00, 16.43it/s, loss=0.487, v_num=0]\n",
      "Epoch 10: 100%|██████████| 174/174 [00:10<00:00, 16.69it/s, loss=0.487, v_num=0]\n",
      "Epoch 11:  78%|███████▊  | 136/174 [00:09<00:02, 14.75it/s, loss=0.488, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  80%|████████  | 140/174 [00:09<00:02, 14.94it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  83%|████████▎ | 144/174 [00:09<00:01, 15.16it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  85%|████████▌ | 148/174 [00:09<00:01, 15.38it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  87%|████████▋ | 152/174 [00:09<00:01, 15.60it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  90%|████████▉ | 156/174 [00:09<00:01, 15.80it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  92%|█████████▏| 160/174 [00:09<00:00, 16.00it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  94%|█████████▍| 164/174 [00:10<00:00, 16.19it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  97%|█████████▋| 168/174 [00:10<00:00, 16.38it/s, loss=0.488, v_num=0]\n",
      "Epoch 11:  99%|█████████▉| 172/174 [00:10<00:00, 16.56it/s, loss=0.488, v_num=0]\n",
      "Epoch 11: 100%|██████████| 174/174 [00:10<00:00, 16.63it/s, loss=0.488, v_num=0]\n",
      "Epoch 12:  78%|███████▊  | 136/174 [00:09<00:02, 14.61it/s, loss=0.486, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  80%|████████  | 140/174 [00:09<00:02, 14.81it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  83%|████████▎ | 144/174 [00:09<00:01, 15.04it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  85%|████████▌ | 148/174 [00:09<00:01, 15.26it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  87%|████████▋ | 152/174 [00:09<00:01, 15.47it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  90%|████████▉ | 156/174 [00:09<00:01, 15.68it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  92%|█████████▏| 160/174 [00:10<00:00, 15.88it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  94%|█████████▍| 164/174 [00:10<00:00, 16.08it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  97%|█████████▋| 168/174 [00:10<00:00, 16.27it/s, loss=0.486, v_num=0]\n",
      "Epoch 12:  99%|█████████▉| 172/174 [00:10<00:00, 16.46it/s, loss=0.486, v_num=0]\n",
      "Epoch 12: 100%|██████████| 174/174 [00:10<00:00, 16.53it/s, loss=0.486, v_num=0]\n",
      "Epoch 13:  78%|███████▊  | 136/174 [00:09<00:02, 14.64it/s, loss=0.479, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  80%|████████  | 140/174 [00:09<00:02, 14.83it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  83%|████████▎ | 144/174 [00:09<00:01, 15.05it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  85%|████████▌ | 148/174 [00:09<00:01, 15.27it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  87%|████████▋ | 152/174 [00:09<00:01, 15.48it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  90%|████████▉ | 156/174 [00:09<00:01, 15.69it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  92%|█████████▏| 160/174 [00:10<00:00, 15.90it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  94%|█████████▍| 164/174 [00:10<00:00, 16.09it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  97%|█████████▋| 168/174 [00:10<00:00, 16.29it/s, loss=0.479, v_num=0]\n",
      "Epoch 13:  99%|█████████▉| 172/174 [00:10<00:00, 16.48it/s, loss=0.479, v_num=0]\n",
      "Epoch 13: 100%|██████████| 174/174 [00:10<00:00, 16.55it/s, loss=0.479, v_num=0]\n",
      "Epoch 14:  78%|███████▊  | 136/174 [00:09<00:02, 14.67it/s, loss=0.473, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  80%|████████  | 140/174 [00:09<00:02, 14.86it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  83%|████████▎ | 144/174 [00:09<00:01, 15.09it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  85%|████████▌ | 148/174 [00:09<00:01, 15.31it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  87%|████████▋ | 152/174 [00:09<00:01, 15.52it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  90%|████████▉ | 156/174 [00:09<00:01, 15.73it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  92%|█████████▏| 160/174 [00:10<00:00, 15.94it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  94%|█████████▍| 164/174 [00:10<00:00, 16.14it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  97%|█████████▋| 168/174 [00:10<00:00, 16.33it/s, loss=0.473, v_num=0]\n",
      "Epoch 14:  99%|█████████▉| 172/174 [00:10<00:00, 16.52it/s, loss=0.473, v_num=0]\n",
      "Epoch 14: 100%|██████████| 174/174 [00:10<00:00, 16.59it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  78%|███████▊  | 136/174 [00:09<00:02, 14.81it/s, loss=0.473, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  83%|████████▎ | 144/174 [00:09<00:01, 15.24it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  85%|████████▌ | 148/174 [00:09<00:01, 15.46it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  87%|████████▋ | 152/174 [00:09<00:01, 15.68it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  90%|████████▉ | 156/174 [00:09<00:01, 15.89it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  92%|█████████▏| 160/174 [00:09<00:00, 16.09it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  94%|█████████▍| 164/174 [00:10<00:00, 16.29it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  97%|█████████▋| 168/174 [00:10<00:00, 16.47it/s, loss=0.473, v_num=0]\n",
      "Epoch 15:  99%|█████████▉| 172/174 [00:10<00:00, 16.65it/s, loss=0.473, v_num=0]\n",
      "Epoch 15: 100%|██████████| 174/174 [00:10<00:00, 16.72it/s, loss=0.473, v_num=0]\n",
      "Epoch 16:  78%|███████▊  | 136/174 [00:09<00:02, 14.83it/s, loss=0.48, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  80%|████████  | 140/174 [00:09<00:02, 15.04it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  83%|████████▎ | 144/174 [00:09<00:01, 15.27it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  85%|████████▌ | 148/174 [00:09<00:01, 15.49it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  87%|████████▋ | 152/174 [00:09<00:01, 15.70it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  90%|████████▉ | 156/174 [00:09<00:01, 15.91it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  92%|█████████▏| 160/174 [00:09<00:00, 16.12it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  94%|█████████▍| 164/174 [00:10<00:00, 16.32it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  97%|█████████▋| 168/174 [00:10<00:00, 16.51it/s, loss=0.48, v_num=0]\n",
      "Epoch 16:  99%|█████████▉| 172/174 [00:10<00:00, 16.70it/s, loss=0.48, v_num=0]\n",
      "Epoch 16: 100%|██████████| 174/174 [00:10<00:00, 16.77it/s, loss=0.48, v_num=0]\n",
      "Epoch 17:  78%|███████▊  | 136/174 [00:09<00:02, 14.81it/s, loss=0.477, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  83%|████████▎ | 144/174 [00:09<00:01, 15.25it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  85%|████████▌ | 148/174 [00:09<00:01, 15.47it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  87%|████████▋ | 152/174 [00:09<00:01, 15.69it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  90%|████████▉ | 156/174 [00:09<00:01, 15.90it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  92%|█████████▏| 160/174 [00:09<00:00, 16.10it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  94%|█████████▍| 164/174 [00:10<00:00, 16.30it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  97%|█████████▋| 168/174 [00:10<00:00, 16.49it/s, loss=0.477, v_num=0]\n",
      "Epoch 17:  99%|█████████▉| 172/174 [00:10<00:00, 16.67it/s, loss=0.477, v_num=0]\n",
      "Epoch 17: 100%|██████████| 174/174 [00:10<00:00, 16.73it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  78%|███████▊  | 136/174 [00:09<00:02, 14.81it/s, loss=0.477, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  83%|████████▎ | 144/174 [00:09<00:01, 15.25it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  85%|████████▌ | 148/174 [00:09<00:01, 15.47it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  87%|████████▋ | 152/174 [00:09<00:01, 15.68it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  90%|████████▉ | 156/174 [00:09<00:01, 15.89it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  92%|█████████▏| 160/174 [00:09<00:00, 16.10it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  94%|█████████▍| 164/174 [00:10<00:00, 16.30it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  97%|█████████▋| 168/174 [00:10<00:00, 16.49it/s, loss=0.477, v_num=0]\n",
      "Epoch 18:  99%|█████████▉| 172/174 [00:10<00:00, 16.68it/s, loss=0.477, v_num=0]\n",
      "Epoch 18: 100%|██████████| 174/174 [00:10<00:00, 16.75it/s, loss=0.477, v_num=0]\n",
      "Epoch 19:  78%|███████▊  | 136/174 [00:09<00:02, 14.84it/s, loss=0.478, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  80%|████████  | 140/174 [00:09<00:02, 15.05it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  83%|████████▎ | 144/174 [00:09<00:01, 15.28it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  85%|████████▌ | 148/174 [00:09<00:01, 15.50it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  87%|████████▋ | 152/174 [00:09<00:01, 15.71it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  90%|████████▉ | 156/174 [00:09<00:01, 15.92it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  92%|█████████▏| 160/174 [00:09<00:00, 16.13it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  94%|█████████▍| 164/174 [00:10<00:00, 16.33it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  97%|█████████▋| 168/174 [00:10<00:00, 16.52it/s, loss=0.478, v_num=0]\n",
      "Epoch 19:  99%|█████████▉| 172/174 [00:10<00:00, 16.71it/s, loss=0.478, v_num=0]\n",
      "Epoch 19: 100%|██████████| 174/174 [00:10<00:00, 16.77it/s, loss=0.478, v_num=0]\n",
      "Epoch 20:  78%|███████▊  | 136/174 [00:09<00:02, 14.47it/s, loss=0.464, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  80%|████████  | 140/174 [00:09<00:02, 14.68it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  83%|████████▎ | 144/174 [00:09<00:02, 14.91it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  85%|████████▌ | 148/174 [00:09<00:01, 15.12it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  87%|████████▋ | 152/174 [00:09<00:01, 15.34it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  90%|████████▉ | 156/174 [00:10<00:01, 15.53it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  92%|█████████▏| 160/174 [00:10<00:00, 15.74it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  94%|█████████▍| 164/174 [00:10<00:00, 15.93it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  97%|█████████▋| 168/174 [00:10<00:00, 16.11it/s, loss=0.464, v_num=0]\n",
      "Epoch 20:  99%|█████████▉| 172/174 [00:10<00:00, 16.30it/s, loss=0.464, v_num=0]\n",
      "Epoch 20: 100%|██████████| 174/174 [00:10<00:00, 16.37it/s, loss=0.464, v_num=0]\n",
      "Epoch 21:  78%|███████▊  | 136/174 [00:09<00:02, 14.83it/s, loss=0.468, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  80%|████████  | 140/174 [00:09<00:02, 15.04it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  83%|████████▎ | 144/174 [00:09<00:01, 15.27it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  85%|████████▌ | 148/174 [00:09<00:01, 15.49it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  87%|████████▋ | 152/174 [00:09<00:01, 15.70it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  90%|████████▉ | 156/174 [00:09<00:01, 15.91it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  92%|█████████▏| 160/174 [00:09<00:00, 16.12it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  94%|█████████▍| 164/174 [00:10<00:00, 16.31it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  97%|█████████▋| 168/174 [00:10<00:00, 16.50it/s, loss=0.468, v_num=0]\n",
      "Epoch 21:  99%|█████████▉| 172/174 [00:10<00:00, 16.68it/s, loss=0.468, v_num=0]\n",
      "Epoch 21: 100%|██████████| 174/174 [00:10<00:00, 16.75it/s, loss=0.468, v_num=0]\n",
      "Epoch 22:  78%|███████▊  | 136/174 [00:09<00:02, 14.85it/s, loss=0.46, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  80%|████████  | 140/174 [00:09<00:02, 15.04it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  83%|████████▎ | 144/174 [00:09<00:01, 15.27it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  85%|████████▌ | 148/174 [00:09<00:01, 15.49it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  87%|████████▋ | 152/174 [00:09<00:01, 15.70it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  90%|████████▉ | 156/174 [00:09<00:01, 15.91it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  92%|█████████▏| 160/174 [00:09<00:00, 16.10it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  94%|█████████▍| 164/174 [00:10<00:00, 16.29it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  97%|█████████▋| 168/174 [00:10<00:00, 16.48it/s, loss=0.46, v_num=0]\n",
      "Epoch 22:  99%|█████████▉| 172/174 [00:10<00:00, 16.67it/s, loss=0.46, v_num=0]\n",
      "Epoch 22: 100%|██████████| 174/174 [00:10<00:00, 16.74it/s, loss=0.46, v_num=0]\n",
      "Epoch 23:  78%|███████▊  | 136/174 [00:09<00:02, 14.84it/s, loss=0.468, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  80%|████████  | 140/174 [00:09<00:02, 15.05it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  83%|████████▎ | 144/174 [00:09<00:01, 15.27it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  85%|████████▌ | 148/174 [00:09<00:01, 15.49it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  87%|████████▋ | 152/174 [00:09<00:01, 15.71it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  90%|████████▉ | 156/174 [00:09<00:01, 15.92it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  92%|█████████▏| 160/174 [00:09<00:00, 16.12it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  94%|█████████▍| 164/174 [00:10<00:00, 16.32it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  97%|█████████▋| 168/174 [00:10<00:00, 16.52it/s, loss=0.468, v_num=0]\n",
      "Epoch 23:  99%|█████████▉| 172/174 [00:10<00:00, 16.70it/s, loss=0.468, v_num=0]\n",
      "Epoch 23: 100%|██████████| 174/174 [00:10<00:00, 16.78it/s, loss=0.468, v_num=0]\n",
      "Epoch 24:  78%|███████▊  | 136/174 [00:09<00:02, 14.88it/s, loss=0.472, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  80%|████████  | 140/174 [00:09<00:02, 15.07it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  83%|████████▎ | 144/174 [00:09<00:01, 15.30it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  85%|████████▌ | 148/174 [00:09<00:01, 15.52it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  87%|████████▋ | 152/174 [00:09<00:01, 15.73it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  90%|████████▉ | 156/174 [00:09<00:01, 15.94it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  92%|█████████▏| 160/174 [00:09<00:00, 16.15it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  94%|█████████▍| 164/174 [00:10<00:00, 16.35it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  97%|█████████▋| 168/174 [00:10<00:00, 16.54it/s, loss=0.472, v_num=0]\n",
      "Epoch 24:  99%|█████████▉| 172/174 [00:10<00:00, 16.73it/s, loss=0.472, v_num=0]\n",
      "Epoch 24: 100%|██████████| 174/174 [00:10<00:00, 16.80it/s, loss=0.472, v_num=0]\n",
      "Epoch 25:  78%|███████▊  | 136/174 [00:09<00:02, 14.84it/s, loss=0.459, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  80%|████████  | 140/174 [00:09<00:02, 15.05it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  83%|████████▎ | 144/174 [00:09<00:01, 15.28it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  85%|████████▌ | 148/174 [00:09<00:01, 15.50it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  87%|████████▋ | 152/174 [00:09<00:01, 15.71it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  90%|████████▉ | 156/174 [00:09<00:01, 15.90it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  92%|█████████▏| 160/174 [00:09<00:00, 16.11it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  94%|█████████▍| 164/174 [00:10<00:00, 16.30it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  97%|█████████▋| 168/174 [00:10<00:00, 16.50it/s, loss=0.459, v_num=0]\n",
      "Epoch 25:  99%|█████████▉| 172/174 [00:10<00:00, 16.69it/s, loss=0.459, v_num=0]\n",
      "Epoch 25: 100%|██████████| 174/174 [00:10<00:00, 16.76it/s, loss=0.459, v_num=0]\n",
      "Epoch 26:  78%|███████▊  | 136/174 [00:09<00:02, 14.56it/s, loss=0.461, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  80%|████████  | 140/174 [00:09<00:02, 14.74it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  83%|████████▎ | 144/174 [00:09<00:02, 14.96it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  85%|████████▌ | 148/174 [00:09<00:01, 15.18it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  87%|████████▋ | 152/174 [00:09<00:01, 15.40it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  90%|████████▉ | 156/174 [00:10<00:01, 15.60it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  92%|█████████▏| 160/174 [00:10<00:00, 15.80it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  94%|█████████▍| 164/174 [00:10<00:00, 15.99it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  97%|█████████▋| 168/174 [00:10<00:00, 16.17it/s, loss=0.461, v_num=0]\n",
      "Epoch 26:  99%|█████████▉| 172/174 [00:10<00:00, 16.36it/s, loss=0.461, v_num=0]\n",
      "Epoch 26: 100%|██████████| 174/174 [00:10<00:00, 16.43it/s, loss=0.461, v_num=0]\n",
      "Epoch 27:  78%|███████▊  | 136/174 [00:09<00:02, 14.72it/s, loss=0.459, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  80%|████████  | 140/174 [00:09<00:02, 14.91it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  83%|████████▎ | 144/174 [00:09<00:01, 15.14it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  85%|████████▌ | 148/174 [00:09<00:01, 15.36it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  87%|████████▋ | 152/174 [00:09<00:01, 15.57it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  90%|████████▉ | 156/174 [00:09<00:01, 15.77it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  92%|█████████▏| 160/174 [00:10<00:00, 15.98it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  94%|█████████▍| 164/174 [00:10<00:00, 16.17it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  97%|█████████▋| 168/174 [00:10<00:00, 16.37it/s, loss=0.459, v_num=0]\n",
      "Epoch 27:  99%|█████████▉| 172/174 [00:10<00:00, 16.56it/s, loss=0.459, v_num=0]\n",
      "Epoch 27: 100%|██████████| 174/174 [00:10<00:00, 16.62it/s, loss=0.459, v_num=0]\n",
      "Epoch 28:  78%|███████▊  | 136/174 [00:09<00:02, 14.64it/s, loss=0.453, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  80%|████████  | 140/174 [00:09<00:02, 14.83it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  83%|████████▎ | 144/174 [00:09<00:01, 15.06it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  85%|████████▌ | 148/174 [00:09<00:01, 15.28it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  87%|████████▋ | 152/174 [00:09<00:01, 15.49it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  90%|████████▉ | 156/174 [00:09<00:01, 15.70it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  92%|█████████▏| 160/174 [00:10<00:00, 15.90it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  94%|█████████▍| 164/174 [00:10<00:00, 16.10it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  97%|█████████▋| 168/174 [00:10<00:00, 16.28it/s, loss=0.453, v_num=0]\n",
      "Epoch 28:  99%|█████████▉| 172/174 [00:10<00:00, 16.46it/s, loss=0.453, v_num=0]\n",
      "Epoch 28: 100%|██████████| 174/174 [00:10<00:00, 16.52it/s, loss=0.453, v_num=0]\n",
      "Epoch 29:  78%|███████▊  | 136/174 [00:09<00:02, 14.60it/s, loss=0.457, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  80%|████████  | 140/174 [00:09<00:02, 14.80it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  83%|████████▎ | 144/174 [00:09<00:01, 15.02it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  85%|████████▌ | 148/174 [00:09<00:01, 15.24it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  87%|████████▋ | 152/174 [00:09<00:01, 15.45it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  90%|████████▉ | 156/174 [00:09<00:01, 15.66it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  92%|█████████▏| 160/174 [00:10<00:00, 15.86it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  94%|█████████▍| 164/174 [00:10<00:00, 16.05it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  97%|█████████▋| 168/174 [00:10<00:00, 16.23it/s, loss=0.457, v_num=0]\n",
      "Epoch 29:  99%|█████████▉| 172/174 [00:10<00:00, 16.42it/s, loss=0.457, v_num=0]\n",
      "Epoch 29: 100%|██████████| 174/174 [00:10<00:00, 16.49it/s, loss=0.457, v_num=0]\n",
      "Epoch 30:  78%|███████▊  | 136/174 [00:09<00:02, 14.74it/s, loss=0.459, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  80%|████████  | 140/174 [00:09<00:02, 14.94it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  83%|████████▎ | 144/174 [00:09<00:01, 15.17it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  85%|████████▌ | 148/174 [00:09<00:01, 15.39it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  87%|████████▋ | 152/174 [00:09<00:01, 15.60it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  90%|████████▉ | 156/174 [00:09<00:01, 15.81it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  92%|█████████▏| 160/174 [00:09<00:00, 16.01it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  94%|█████████▍| 164/174 [00:10<00:00, 16.20it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  97%|█████████▋| 168/174 [00:10<00:00, 16.40it/s, loss=0.459, v_num=0]\n",
      "Epoch 30:  99%|█████████▉| 172/174 [00:10<00:00, 16.58it/s, loss=0.459, v_num=0]\n",
      "Epoch 30: 100%|██████████| 174/174 [00:10<00:00, 16.65it/s, loss=0.459, v_num=0]\n",
      "Epoch 31:  78%|███████▊  | 136/174 [00:09<00:02, 14.69it/s, loss=0.458, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  80%|████████  | 140/174 [00:09<00:02, 14.89it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  83%|████████▎ | 144/174 [00:09<00:01, 15.12it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  85%|████████▌ | 148/174 [00:09<00:01, 15.34it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  87%|████████▋ | 152/174 [00:09<00:01, 15.55it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  90%|████████▉ | 156/174 [00:09<00:01, 15.76it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  92%|█████████▏| 160/174 [00:10<00:00, 15.97it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  94%|█████████▍| 164/174 [00:10<00:00, 16.17it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  97%|█████████▋| 168/174 [00:10<00:00, 16.36it/s, loss=0.458, v_num=0]\n",
      "Epoch 31:  99%|█████████▉| 172/174 [00:10<00:00, 16.54it/s, loss=0.458, v_num=0]\n",
      "Epoch 31: 100%|██████████| 174/174 [00:10<00:00, 16.61it/s, loss=0.458, v_num=0]\n",
      "Epoch 32:  78%|███████▊  | 136/174 [00:09<00:02, 14.67it/s, loss=0.455, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  80%|████████  | 140/174 [00:09<00:02, 14.78it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  83%|████████▎ | 144/174 [00:09<00:02, 14.99it/s, loss=0.455, v_num=0]\n",
      "Validating:  23%|██▎       | 9/39 [00:00<00:01, 26.33it/s]\u001b[A\n",
      "Epoch 32:  85%|████████▌ | 148/174 [00:09<00:01, 15.16it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  87%|████████▋ | 152/174 [00:09<00:01, 15.30it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  90%|████████▉ | 156/174 [00:10<00:01, 15.50it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  92%|█████████▏| 160/174 [00:10<00:00, 15.70it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  94%|█████████▍| 164/174 [00:10<00:00, 15.90it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  97%|█████████▋| 168/174 [00:10<00:00, 16.09it/s, loss=0.455, v_num=0]\n",
      "Epoch 32:  99%|█████████▉| 172/174 [00:10<00:00, 16.28it/s, loss=0.455, v_num=0]\n",
      "Epoch 32: 100%|██████████| 174/174 [00:10<00:00, 16.35it/s, loss=0.455, v_num=0]\n",
      "Epoch 33:  78%|███████▊  | 136/174 [00:09<00:02, 14.78it/s, loss=0.45, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  80%|████████  | 140/174 [00:09<00:02, 14.97it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  83%|████████▎ | 144/174 [00:09<00:01, 15.19it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  85%|████████▌ | 148/174 [00:09<00:01, 15.41it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  87%|████████▋ | 152/174 [00:09<00:01, 15.63it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  90%|████████▉ | 156/174 [00:09<00:01, 15.83it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  92%|█████████▏| 160/174 [00:09<00:00, 16.02it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  94%|█████████▍| 164/174 [00:10<00:00, 16.22it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  97%|█████████▋| 168/174 [00:10<00:00, 16.41it/s, loss=0.45, v_num=0]\n",
      "Epoch 33:  99%|█████████▉| 172/174 [00:10<00:00, 16.60it/s, loss=0.45, v_num=0]\n",
      "Epoch 33: 100%|██████████| 174/174 [00:10<00:00, 16.67it/s, loss=0.45, v_num=0]\n",
      "Epoch 34:  78%|███████▊  | 136/174 [00:09<00:02, 14.82it/s, loss=0.449, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  83%|████████▎ | 144/174 [00:09<00:01, 15.25it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  85%|████████▌ | 148/174 [00:09<00:01, 15.46it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  87%|████████▋ | 152/174 [00:09<00:01, 15.68it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  90%|████████▉ | 156/174 [00:09<00:01, 15.89it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  92%|█████████▏| 160/174 [00:09<00:00, 16.08it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  94%|█████████▍| 164/174 [00:10<00:00, 16.27it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  97%|█████████▋| 168/174 [00:10<00:00, 16.46it/s, loss=0.449, v_num=0]\n",
      "Epoch 34:  99%|█████████▉| 172/174 [00:10<00:00, 16.65it/s, loss=0.449, v_num=0]\n",
      "Epoch 34: 100%|██████████| 174/174 [00:10<00:00, 16.72it/s, loss=0.449, v_num=0]\n",
      "Epoch 35:  78%|███████▊  | 136/174 [00:09<00:02, 14.71it/s, loss=0.451, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  80%|████████  | 140/174 [00:09<00:02, 14.91it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  83%|████████▎ | 144/174 [00:09<00:01, 15.14it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  85%|████████▌ | 148/174 [00:09<00:01, 15.36it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  87%|████████▋ | 152/174 [00:09<00:01, 15.56it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  90%|████████▉ | 156/174 [00:09<00:01, 15.77it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  92%|█████████▏| 160/174 [00:10<00:00, 15.96it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  94%|█████████▍| 164/174 [00:10<00:00, 16.16it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  97%|█████████▋| 168/174 [00:10<00:00, 16.35it/s, loss=0.451, v_num=0]\n",
      "Epoch 35:  99%|█████████▉| 172/174 [00:10<00:00, 16.54it/s, loss=0.451, v_num=0]\n",
      "Epoch 35: 100%|██████████| 174/174 [00:10<00:00, 16.61it/s, loss=0.451, v_num=0]\n",
      "Epoch 36:  78%|███████▊  | 136/174 [00:09<00:02, 14.72it/s, loss=0.445, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  80%|████████  | 140/174 [00:09<00:02, 14.93it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  83%|████████▎ | 144/174 [00:09<00:01, 15.16it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  85%|████████▌ | 148/174 [00:09<00:01, 15.38it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  87%|████████▋ | 152/174 [00:09<00:01, 15.59it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  90%|████████▉ | 156/174 [00:09<00:01, 15.79it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  92%|█████████▏| 160/174 [00:10<00:00, 16.00it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  94%|█████████▍| 164/174 [00:10<00:00, 16.20it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  97%|█████████▋| 168/174 [00:10<00:00, 16.39it/s, loss=0.445, v_num=0]\n",
      "Epoch 36:  99%|█████████▉| 172/174 [00:10<00:00, 16.57it/s, loss=0.445, v_num=0]\n",
      "Epoch 36: 100%|██████████| 174/174 [00:10<00:00, 16.65it/s, loss=0.445, v_num=0]\n",
      "Epoch 37:  78%|███████▊  | 136/174 [00:09<00:02, 14.75it/s, loss=0.457, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  80%|████████  | 140/174 [00:09<00:02, 14.95it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  83%|████████▎ | 144/174 [00:09<00:01, 15.18it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  85%|████████▌ | 148/174 [00:09<00:01, 15.39it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  87%|████████▋ | 152/174 [00:09<00:01, 15.61it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  90%|████████▉ | 156/174 [00:09<00:01, 15.82it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  92%|█████████▏| 160/174 [00:09<00:00, 16.01it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  94%|█████████▍| 164/174 [00:10<00:00, 16.20it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  97%|█████████▋| 168/174 [00:10<00:00, 16.39it/s, loss=0.457, v_num=0]\n",
      "Epoch 37:  99%|█████████▉| 172/174 [00:10<00:00, 16.58it/s, loss=0.457, v_num=0]\n",
      "Epoch 37: 100%|██████████| 174/174 [00:10<00:00, 16.66it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  78%|███████▊  | 136/174 [00:09<00:02, 14.84it/s, loss=0.457, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  80%|████████  | 140/174 [00:09<00:02, 15.02it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  83%|████████▎ | 144/174 [00:09<00:01, 15.24it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  85%|████████▌ | 148/174 [00:09<00:01, 15.45it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  87%|████████▋ | 152/174 [00:09<00:01, 15.65it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  90%|████████▉ | 156/174 [00:09<00:01, 15.85it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  92%|█████████▏| 160/174 [00:09<00:00, 16.05it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  94%|█████████▍| 164/174 [00:10<00:00, 16.25it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  97%|█████████▋| 168/174 [00:10<00:00, 16.44it/s, loss=0.457, v_num=0]\n",
      "Epoch 38:  99%|█████████▉| 172/174 [00:10<00:00, 16.63it/s, loss=0.457, v_num=0]\n",
      "Epoch 38: 100%|██████████| 174/174 [00:10<00:00, 16.70it/s, loss=0.457, v_num=0]\n",
      "Epoch 39:  78%|███████▊  | 136/174 [00:09<00:02, 14.86it/s, loss=0.452, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  80%|████████  | 140/174 [00:09<00:02, 15.05it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  83%|████████▎ | 144/174 [00:09<00:01, 15.28it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  85%|████████▌ | 148/174 [00:09<00:01, 15.50it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  87%|████████▋ | 152/174 [00:09<00:01, 15.71it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  90%|████████▉ | 156/174 [00:09<00:01, 15.92it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  92%|█████████▏| 160/174 [00:09<00:00, 16.12it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  94%|█████████▍| 164/174 [00:10<00:00, 16.32it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  97%|█████████▋| 168/174 [00:10<00:00, 16.51it/s, loss=0.452, v_num=0]\n",
      "Epoch 39:  99%|█████████▉| 172/174 [00:10<00:00, 16.70it/s, loss=0.452, v_num=0]\n",
      "Epoch 39: 100%|██████████| 174/174 [00:10<00:00, 16.77it/s, loss=0.452, v_num=0]\n",
      "Epoch 40:  78%|███████▊  | 136/174 [00:09<00:02, 14.78it/s, loss=0.449, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  80%|████████  | 140/174 [00:09<00:02, 14.97it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  83%|████████▎ | 144/174 [00:09<00:01, 15.19it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  85%|████████▌ | 148/174 [00:09<00:01, 15.41it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  87%|████████▋ | 152/174 [00:09<00:01, 15.62it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  90%|████████▉ | 156/174 [00:09<00:01, 15.83it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  92%|█████████▏| 160/174 [00:09<00:00, 16.03it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  94%|█████████▍| 164/174 [00:10<00:00, 16.22it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  97%|█████████▋| 168/174 [00:10<00:00, 16.41it/s, loss=0.449, v_num=0]\n",
      "Epoch 40:  99%|█████████▉| 172/174 [00:10<00:00, 16.60it/s, loss=0.449, v_num=0]\n",
      "Epoch 40: 100%|██████████| 174/174 [00:10<00:00, 16.67it/s, loss=0.449, v_num=0]\n",
      "Epoch 41:  78%|███████▊  | 136/174 [00:09<00:02, 14.89it/s, loss=0.455, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  80%|████████  | 140/174 [00:09<00:02, 15.11it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  83%|████████▎ | 144/174 [00:09<00:01, 15.33it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  85%|████████▌ | 148/174 [00:09<00:01, 15.55it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  87%|████████▋ | 152/174 [00:09<00:01, 15.76it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  90%|████████▉ | 156/174 [00:09<00:01, 15.96it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  92%|█████████▏| 160/174 [00:09<00:00, 16.16it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  94%|█████████▍| 164/174 [00:10<00:00, 16.36it/s, loss=0.455, v_num=0]\n",
      "Epoch 41:  97%|█████████▋| 168/174 [00:10<00:00, 16.55it/s, loss=0.455, v_num=0]\n",
      "Epoch 41: 100%|██████████| 174/174 [00:10<00:00, 16.81it/s, loss=0.455, v_num=0]\n",
      "Epoch 42:  78%|███████▊  | 136/174 [00:09<00:02, 14.67it/s, loss=0.452, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  80%|████████  | 140/174 [00:09<00:02, 14.87it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  83%|████████▎ | 144/174 [00:09<00:01, 15.09it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  85%|████████▌ | 148/174 [00:09<00:01, 15.31it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  87%|████████▋ | 152/174 [00:09<00:01, 15.52it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  90%|████████▉ | 156/174 [00:09<00:01, 15.72it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  92%|█████████▏| 160/174 [00:10<00:00, 15.92it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  94%|█████████▍| 164/174 [00:10<00:00, 16.12it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  97%|█████████▋| 168/174 [00:10<00:00, 16.31it/s, loss=0.452, v_num=0]\n",
      "Epoch 42:  99%|█████████▉| 172/174 [00:10<00:00, 16.48it/s, loss=0.452, v_num=0]\n",
      "Epoch 42: 100%|██████████| 174/174 [00:10<00:00, 16.55it/s, loss=0.452, v_num=0]\n",
      "Epoch 43:  78%|███████▊  | 136/174 [00:09<00:02, 14.77it/s, loss=0.444, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  80%|████████  | 140/174 [00:09<00:02, 14.96it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  83%|████████▎ | 144/174 [00:09<00:01, 15.18it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  85%|████████▌ | 148/174 [00:09<00:01, 15.40it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  87%|████████▋ | 152/174 [00:09<00:01, 15.61it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  90%|████████▉ | 156/174 [00:09<00:01, 15.81it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  92%|█████████▏| 160/174 [00:09<00:00, 16.02it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  94%|█████████▍| 164/174 [00:10<00:00, 16.21it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  97%|█████████▋| 168/174 [00:10<00:00, 16.40it/s, loss=0.444, v_num=0]\n",
      "Epoch 43:  99%|█████████▉| 172/174 [00:10<00:00, 16.58it/s, loss=0.444, v_num=0]\n",
      "Epoch 43: 100%|██████████| 174/174 [00:10<00:00, 16.64it/s, loss=0.444, v_num=0]\n",
      "Epoch 44:  78%|███████▊  | 136/174 [00:09<00:02, 14.59it/s, loss=0.456, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  80%|████████  | 140/174 [00:09<00:02, 14.80it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  83%|████████▎ | 144/174 [00:09<00:01, 15.02it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  85%|████████▌ | 148/174 [00:09<00:01, 15.24it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  87%|████████▋ | 152/174 [00:09<00:01, 15.46it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  90%|████████▉ | 156/174 [00:09<00:01, 15.67it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  92%|█████████▏| 160/174 [00:10<00:00, 15.87it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  94%|█████████▍| 164/174 [00:10<00:00, 16.06it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  97%|█████████▋| 168/174 [00:10<00:00, 16.25it/s, loss=0.456, v_num=0]\n",
      "Epoch 44:  99%|█████████▉| 172/174 [00:10<00:00, 16.44it/s, loss=0.456, v_num=0]\n",
      "Epoch 44: 100%|██████████| 174/174 [00:10<00:00, 16.51it/s, loss=0.456, v_num=0]\n",
      "Epoch 45:  78%|███████▊  | 136/174 [00:09<00:02, 14.74it/s, loss=0.444, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  80%|████████  | 140/174 [00:09<00:02, 14.95it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  83%|████████▎ | 144/174 [00:09<00:01, 15.17it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  85%|████████▌ | 148/174 [00:09<00:01, 15.39it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  87%|████████▋ | 152/174 [00:09<00:01, 15.60it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  90%|████████▉ | 156/174 [00:09<00:01, 15.81it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  92%|█████████▏| 160/174 [00:09<00:00, 16.00it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  94%|█████████▍| 164/174 [00:10<00:00, 16.20it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  97%|█████████▋| 168/174 [00:10<00:00, 16.39it/s, loss=0.444, v_num=0]\n",
      "Epoch 45:  99%|█████████▉| 172/174 [00:10<00:00, 16.58it/s, loss=0.444, v_num=0]\n",
      "Epoch 45: 100%|██████████| 174/174 [00:10<00:00, 16.65it/s, loss=0.444, v_num=0]\n",
      "Epoch 46:  78%|███████▊  | 136/174 [00:09<00:02, 14.77it/s, loss=0.443, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  80%|████████  | 140/174 [00:09<00:02, 14.97it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  83%|████████▎ | 144/174 [00:09<00:01, 15.19it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  85%|████████▌ | 148/174 [00:09<00:01, 15.41it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  87%|████████▋ | 152/174 [00:09<00:01, 15.63it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  90%|████████▉ | 156/174 [00:09<00:01, 15.84it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  92%|█████████▏| 160/174 [00:09<00:00, 16.04it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  94%|█████████▍| 164/174 [00:10<00:00, 16.24it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  97%|█████████▋| 168/174 [00:10<00:00, 16.43it/s, loss=0.443, v_num=0]\n",
      "Epoch 46:  99%|█████████▉| 172/174 [00:10<00:00, 16.62it/s, loss=0.443, v_num=0]\n",
      "Epoch 46: 100%|██████████| 174/174 [00:10<00:00, 16.69it/s, loss=0.443, v_num=0]\n",
      "Epoch 47:  78%|███████▊  | 136/174 [00:09<00:02, 14.86it/s, loss=0.444, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  80%|████████  | 140/174 [00:09<00:02, 15.05it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  83%|████████▎ | 144/174 [00:09<00:01, 15.28it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  85%|████████▌ | 148/174 [00:09<00:01, 15.49it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  87%|████████▋ | 152/174 [00:09<00:01, 15.71it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  90%|████████▉ | 156/174 [00:09<00:01, 15.91it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  92%|█████████▏| 160/174 [00:09<00:00, 16.11it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  94%|█████████▍| 164/174 [00:10<00:00, 16.30it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  97%|█████████▋| 168/174 [00:10<00:00, 16.48it/s, loss=0.444, v_num=0]\n",
      "Epoch 47:  99%|█████████▉| 172/174 [00:10<00:00, 16.67it/s, loss=0.444, v_num=0]\n",
      "Epoch 47: 100%|██████████| 174/174 [00:10<00:00, 16.74it/s, loss=0.444, v_num=0]\n",
      "Epoch 48:  78%|███████▊  | 136/174 [00:09<00:02, 14.79it/s, loss=0.44, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  80%|████████  | 140/174 [00:09<00:02, 15.00it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  83%|████████▎ | 144/174 [00:09<00:01, 15.22it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  85%|████████▌ | 148/174 [00:09<00:01, 15.44it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  87%|████████▋ | 152/174 [00:09<00:01, 15.66it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  90%|████████▉ | 156/174 [00:09<00:01, 15.86it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  92%|█████████▏| 160/174 [00:09<00:00, 16.06it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  94%|█████████▍| 164/174 [00:10<00:00, 16.26it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  97%|█████████▋| 168/174 [00:10<00:00, 16.46it/s, loss=0.44, v_num=0]\n",
      "Epoch 48:  99%|█████████▉| 172/174 [00:10<00:00, 16.65it/s, loss=0.44, v_num=0]\n",
      "Epoch 48: 100%|██████████| 174/174 [00:10<00:00, 16.72it/s, loss=0.44, v_num=0]\n",
      "Epoch 49:  78%|███████▊  | 136/174 [00:09<00:02, 14.77it/s, loss=0.451, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  80%|████████  | 140/174 [00:09<00:02, 14.98it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  83%|████████▎ | 144/174 [00:09<00:01, 15.20it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  85%|████████▌ | 148/174 [00:09<00:01, 15.42it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  87%|████████▋ | 152/174 [00:09<00:01, 15.64it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  90%|████████▉ | 156/174 [00:09<00:01, 15.84it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  92%|█████████▏| 160/174 [00:09<00:00, 16.04it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  94%|█████████▍| 164/174 [00:10<00:00, 16.23it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  97%|█████████▋| 168/174 [00:10<00:00, 16.42it/s, loss=0.451, v_num=0]\n",
      "Epoch 49:  99%|█████████▉| 172/174 [00:10<00:00, 16.61it/s, loss=0.451, v_num=0]\n",
      "Epoch 49: 100%|██████████| 174/174 [00:10<00:00, 16.68it/s, loss=0.451, v_num=0]\n",
      "Epoch 49: 100%|██████████| 174/174 [00:10<00:00, 16.67it/s, loss=0.451, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN 10 MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "\n",
    "    if cnn_type == '4L':\n",
    "        autoencoder = CNN_UNET_4L()\n",
    "        filename_chkpt = 'CNN_UNET_4L_{0}'.format(i)\n",
    "    elif cnn_type =='surf':\n",
    "\n",
    "        autoencoder = CNN_UNET_SURF()\n",
    "        filename_chkpt = 'CNN_UNET_SURF_{0}'.format(i)\n",
    "        \n",
    "    filename_chkpt = 'CNN_UNET_SURFACE_{0}'.format(i)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='loss_no_filter',\n",
    "                                              dirpath= dirSAVE,\n",
    "                                              filename= filename_chkpt,\n",
    "                                              save_top_k=1,\n",
    "                                              mode='min')\n",
    "\n",
    "    dirLOG = './logs/supermodel/{0}'.format(filename_chkpt)\n",
    "\n",
    "\n",
    "    # TRAINNING \n",
    "    trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "    trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN using 4 vertical levels\n",
    "\n",
    "alpha1 = 0.8\n",
    "alpha2 = 1-0.8\n",
    "nb_dx = 100\n",
    "\n",
    "class CNN_UNET_4L(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(    \n",
    "        nn.Conv2d(76, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(64)\n",
    "             )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(    \n",
    "        nn.Conv2d(64, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.Conv2d(128, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(128)\n",
    "             )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(    \n",
    "        nn.Conv2d(128, 256, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.Conv2d(256, 256, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(256)\n",
    "             )\n",
    "        \n",
    "        self.conv_up1 = nn.Sequential(    \n",
    "        nn.Conv2d(128, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(64, 8, kernel_size = 3, padding = 1, bias=False)\n",
    "             )\n",
    "        \n",
    "        self.conv_up2 = nn.Sequential(    \n",
    "        nn.Conv2d(256, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.Conv2d(128, 128, kernel_size = 3, padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(128)\n",
    "             )\n",
    "        \n",
    "        self.convTrans3 = nn.ConvTranspose2d(256,128,kernel_size = 2,padding = 0,stride=2)\n",
    "        self.convTrans2 = nn.ConvTranspose2d(128,64,kernel_size = 2,padding = 0,stride=2)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.flatten = nn.Flatten(start_dim=2, end_dim=- 1)\n",
    "        self.maxpool2d = nn.MaxPool2d(2)\n",
    "        self.avgpool2d = nn.AvgPool2d(2)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, z, y_filter,y):\n",
    "        \n",
    "        y_pred = torch.zeros(y.shape).to('cuda')\n",
    "        #print(y_pred.device)\n",
    "        y_pred[:,:,49:51,49:51] = 0.25 # Initialisation of y_pred\n",
    "        #print(y_pred.device)\n",
    "        #print(z.device)\n",
    "\n",
    "        y1 = torch.cat((z,y_pred),dim=1) \n",
    "        y1 = self.conv1(y1)\n",
    "        y2 = self.maxpool2d(y1)\n",
    "        y2 = self.conv2(y2)\n",
    "        y3 = self.maxpool2d(y2)\n",
    "        y3 = self.conv3(y3)\n",
    "        \n",
    "        y3 = self.convTrans3(y3)\n",
    "        y3 = torch.cat((y2,y3),dim=1)\n",
    "        y2 = self.conv_up2(y3)\n",
    "        \n",
    "        y2 = self.convTrans2(y2)\n",
    "        y2 = torch.cat((y1,y2),dim=1)\n",
    "        y1 = self.conv_up1(y2)\n",
    "        \n",
    "        y_hat = self.flatten(y1)\n",
    "        y_hat = self.relu(y_hat)\n",
    "        y_hat = self.softmax(torch.log(y_hat+1e-10)) \n",
    "        y_hat = y_hat.view(y_hat.shape[0],8,nb_dx,nb_dx)\n",
    "        \n",
    "        return y_hat \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = 0.001\n",
    "        optimizer = optim.Adam(self.parameters(),lr= lr, betas=(0.5, 0.999),weight_decay=0)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        z, y_f, y = batch\n",
    "        y_hat = self(z,y_f,y)\n",
    "        loss = 0\n",
    "\n",
    "        \n",
    "        for i in range(0,8):\n",
    "            loss = loss + alpha1*Bhatta_loss(y_hat[:,i,:,:], y_f[:,i,:,:]) + alpha2*Bhatta_loss(y_hat[:,i,:,:], y[:,i,:,:])\n",
    "            \n",
    "        loss = loss / 8\n",
    "        \n",
    "        loss_filter_200m = Bhatta_loss(y_hat[:,-1,:,:], y_f[:,-1,:,:])\n",
    "        \n",
    "        self.log(\"loss_train\", loss, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_filter_200m_train\", loss, on_epoch=True, on_step = True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        z, y_f, y = batch\n",
    "        y_hat = self(z,y_f,y)\n",
    "        \n",
    "        loss_filter = 0\n",
    "        loss_no_filter = 0\n",
    "\n",
    "        for i in range(0,8):\n",
    "            loss_filter = loss_filter + Bhatta_loss(y_hat[:,i,:,:], y_f[:,i,:,:])\n",
    "            loss_no_filter = loss_no_filter + Bhatta_loss(y_hat[:,i,:,:], y[:,i,:,:])\n",
    "            \n",
    "        loss_filter = loss_filter / 8\n",
    "        loss_no_filter = loss_no_filter / 8\n",
    "        \n",
    "        loss_filter_200m = Bhatta_loss(y_hat[:,-1,:,:], y_f[:,-1,:,:])\n",
    "        \n",
    "        self.log(\"loss_filter_validation\", loss_filter, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_no_filter_validation\", loss_no_filter, on_epoch=True, on_step = True)\n",
    "        self.log(\"loss_filter_200m_validation\", loss_filter_200m, on_epoch=True, on_step = True)\n",
    "        \n",
    "        return loss_no_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-dcb0ca9d-55d4-28a2-1aa7-2638e1a18e28]\n",
      "\n",
      "   | Name       | Type            | Params\n",
      "------------------------------------------------\n",
      "0  | conv1      | Sequential      | 80.9 K\n",
      "1  | conv2      | Sequential      | 221 K \n",
      "2  | conv3      | Sequential      | 885 K \n",
      "3  | conv_up1   | Sequential      | 115 K \n",
      "4  | conv_up2   | Sequential      | 442 K \n",
      "5  | convTrans3 | ConvTranspose2d | 131 K \n",
      "6  | convTrans2 | ConvTranspose2d | 32.8 K\n",
      "7  | softmax    | Softmax         | 0     \n",
      "8  | flatten    | Flatten         | 0     \n",
      "9  | maxpool2d  | MaxPool2d       | 0     \n",
      "10 | avgpool2d  | AvgPool2d       | 0     \n",
      "11 | relu       | ReLU            | 0     \n",
      "------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.643     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 30/310 [00:09<01:27,  3.21it/s, loss=0.65, v_num=3] "
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "autoencoder = CNN_UNET_4L()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader,val_dataloaders=eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load packages\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import sys\n",
    "import netCDF4 as nc4\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import progressbar\n",
    "sys.path.append(\"/home2/datahome/tpicard/python/Python_Modules_p3_pyticles/\")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def read_input():\n",
    "    nc_name = 'Inputs_vertical_levels_4layers_{0}_sorted.nc'.format(nb_dx)\n",
    "    nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "    inputs_test = np.asfortranarray(nc.variables['inputs_test'])\n",
    "    inputs_train = np.asfortranarray(nc.variables['inputs_train'])\n",
    "    nc.close()\n",
    "    return(inputs_test,inputs_train)\n",
    "\n",
    "def read_output():\n",
    "    \n",
    "    if filt =='L50':\n",
    "        nc_name = 'pdf_4levels_{0}_filter_L50_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test_filter'])\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train_filter'])\n",
    "        \n",
    "    elif filt =='L5':\n",
    "        nc_name = 'pdf_vertical_levels_{0}_filter_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test_filter'])\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train_filter'])\n",
    "        \n",
    "    else :\n",
    "        nc_name = 'pdf_vertical_levels_4layers{0}_sorted.nc'.format(nb_dx)\n",
    "        nc = nc4.Dataset('/home2/datawork/tpicard/Pyticles/CNN_DATA/BACKWARD_CORRECTION/{0}'.format(nc_name),'r')\n",
    "        pdf_test = np.asfortranarray(nc.variables['pdf_test'])*((800/nb_dx)**2)\n",
    "        pdf_train = np.asfortranarray(nc.variables['pdf_train'])*((800/nb_dx)**2)\n",
    "        nc.close()\n",
    "        \n",
    "    return(pdf_test,pdf_train)\n",
    "\n",
    "class Pdf_Image_DataSet(Dataset):\n",
    "    def __init__(self,images, pdf_f,pdf_nf,transform=None):\n",
    "        \n",
    "        self.pdf_f = pdf_f\n",
    "        self.pdf_nf = pdf_nf\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.pdf_f.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # select coordinates\n",
    "        pdf_f_sample = self.pdf_f[idx,1:,0,:,:]\n",
    "        pdf_nf_sample = self.pdf_nf[idx,1:,0,:,:]\n",
    "        image_sample = self.images[idx,:,:,:]\n",
    "        \n",
    "        if self.transform:\n",
    "            pdf_f_sample = self.transform(pdf_f_sample)\n",
    "            pdf_nf_sample = self.transform(pdf_nf_sample)\n",
    "            image_sample = self.transform(image_sample)\n",
    "            \n",
    "        return image_sample, pdf_f_sample, pdf_nf_sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        return torch.FloatTensor(sample)\n",
    "\n",
    "#GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#READ DATA Filter\n",
    "filt = 'L50'\n",
    "(pdf_test_filter,pdf_train_filter) = read_output()\n",
    "(inputs_test,inputs_train) = read_input()\n",
    "\n",
    "#READ DATA No Filter\n",
    "filt = 'No'\n",
    "(pdf_test_no_f,pdf_train_no_f) = read_output()\n",
    "\n",
    "# MEAN and STD for each channel\n",
    "list_mean_train = []\n",
    "list_std_train = []\n",
    "\n",
    "\n",
    "for i in range(inputs_train.shape[1]):\n",
    "    list_mean_train.append(np.mean(inputs_train[:,i,:,:]))\n",
    "    list_std_train.append(np.std(inputs_train[:,i,:,:]))\n",
    "\n",
    "\n",
    "# Normalization of inputs\n",
    "Normalize = transforms.Normalize(list_mean_train, list_std_train)\n",
    "inputs_test = Normalize(torch.tensor(inputs_test))\n",
    "inputs_train = Normalize(torch.tensor(inputs_train))\n",
    "\n",
    "i = 0\n",
    "\n",
    "#inputs_test_1l = np.concatenate((inputs_test[:,4*i:4*i+4,:,:],inputs_test[:,4*i+16:4*i+4+16,:,:],inputs_test[:,4*i+32:4*i+4+32,:,:],inputs_test[:,4*i+48:4*i+4+48,:,:],inputs_test[:,64:,:,:]),axis=1)\n",
    "#inputs_train_1l = np.concatenate((inputs_train[:,4*i:4*i+4,:,:],inputs_train[:,4*i+16:4*i+4+16,:,:],inputs_train[:,4*i+32:4*i+4+32,:,:],inputs_train[:,4*i+48:4*i+4+48,:,:],inputs_train[:,64:,:,:]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## reduce size dataset\n",
    "train_set = Pdf_Image_DataSet(inputs_train,pdf_train_filter,pdf_train_no_f,transform= ToTensor())\n",
    "train_loader_old = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=False)\n",
    "\n",
    "test_set = Pdf_Image_DataSet(inputs_test,pdf_test_filter,pdf_test_no_f,transform= ToTensor())\n",
    "test_loader_old = DataLoader(test_set, batch_size=batch_size, num_workers = 0, shuffle = False, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4900, 68, 100, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900, 9, 1, 100, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_train_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-739dfd1b-f418-cc5b-11cf-7fb8737907b5]\n",
      "\n",
      "   | Name       | Type            | Params\n",
      "------------------------------------------------\n",
      "0  | conv1      | Sequential      | 80.9 K\n",
      "1  | conv2      | Sequential      | 221 K \n",
      "2  | conv3      | Sequential      | 885 K \n",
      "3  | conv_up1   | Sequential      | 115 K \n",
      "4  | conv_up2   | Sequential      | 442 K \n",
      "5  | convTrans3 | ConvTranspose2d | 131 K \n",
      "6  | convTrans2 | ConvTranspose2d | 32.8 K\n",
      "7  | softmax    | Softmax         | 0     \n",
      "8  | flatten    | Flatten         | 0     \n",
      "9  | maxpool2d  | MaxPool2d       | 0     \n",
      "10 | avgpool2d  | AvgPool2d       | 0     \n",
      "11 | relu       | ReLU            | 0     \n",
      "------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.643     Total estimated model params size (MB)\n",
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home2/datahome/tpicard/PhD_MOMOPAR/TRAIN_AND_VALIDATION_CNN/Saved_model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████ | 154/170 [00:35<00:03,  4.29it/s, loss=0.447, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 156/170 [00:36<00:03,  4.32it/s, loss=0.447, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.00it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 159/170 [00:36<00:02,  4.36it/s, loss=0.447, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.48it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 162/170 [00:36<00:01,  4.40it/s, loss=0.447, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 165/170 [00:37<00:01,  4.44it/s, loss=0.447, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.47it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.49it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 168/170 [00:37<00:00,  4.48it/s, loss=0.447, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.24it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 170/170 [00:37<00:00,  4.50it/s, loss=0.447, v_num=6]\n",
      "Epoch 1:  91%|█████████ | 154/170 [00:35<00:03,  4.31it/s, loss=0.342, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 156/170 [00:35<00:03,  4.35it/s, loss=0.342, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.02it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 159/170 [00:36<00:02,  4.39it/s, loss=0.342, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.54it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 162/170 [00:36<00:01,  4.43it/s, loss=0.342, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.31it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 165/170 [00:36<00:01,  4.47it/s, loss=0.342, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.46it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.36it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 168/170 [00:37<00:00,  4.51it/s, loss=0.342, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 170/170 [00:37<00:00,  4.53it/s, loss=0.342, v_num=6]\n",
      "Epoch 2:  91%|█████████ | 154/170 [00:36<00:03,  4.27it/s, loss=0.254, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 156/170 [00:36<00:03,  4.31it/s, loss=0.254, v_num=6]\n",
      "Validating:  12%|█▎        | 2/16 [00:00<00:01,  8.03it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 3/16 [00:00<00:01,  7.99it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 159/170 [00:36<00:02,  4.35it/s, loss=0.254, v_num=6]\n",
      "Validating:  38%|███▊      | 6/16 [00:00<00:01,  8.55it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 162/170 [00:36<00:01,  4.39it/s, loss=0.254, v_num=6]\n",
      "Validating:  50%|█████     | 8/16 [00:00<00:00,  8.30it/s]\u001b[A\n",
      "Validating:  56%|█████▋    | 9/16 [00:01<00:00,  8.54it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 165/170 [00:37<00:01,  4.43it/s, loss=0.254, v_num=6]\n",
      "Validating:  69%|██████▉   | 11/16 [00:01<00:00,  8.29it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 12/16 [00:01<00:00,  8.40it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 168/170 [00:37<00:00,  4.47it/s, loss=0.254, v_num=6]\n",
      "Validating:  88%|████████▊ | 14/16 [00:01<00:00,  8.31it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 170/170 [00:37<00:00,  4.49it/s, loss=0.254, v_num=6]\n",
      "Epoch 3:  21%|██        | 36/170 [00:08<00:31,  4.31it/s, loss=0.247, v_num=6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/datahome/tpicard/conda-env/croco/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  21%|██        | 36/170 [00:25<01:35,  1.40it/s, loss=0.247, v_num=6]"
     ]
    }
   ],
   "source": [
    "# TRAINNING \n",
    "autoencoder = CNN_UNET_4L()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,gpus=nb_gpus, default_root_dir=dirLOG, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader_old,val_dataloaders=test_loader_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-777394afd1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883072\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in CNN_UNET_SURF().parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1910720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croco",
   "language": "python",
   "name": "croco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
